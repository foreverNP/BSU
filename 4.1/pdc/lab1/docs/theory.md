# БЛОЧНЫЕ МАТРИЦЫ. БЛОЧНОЕ ПЕРЕМНОЖЕНИЕ МАТРИЦ. ПАРАЛЛЕЛЬНЫЕ ЦИКЛЫ. СКОШЕННЫЙ ПАРАЛЛЕЛИЗМ

Блочные алгоритмы используются для построения эффективных параллельных алгоритмов и для уменьшения накладных расходов на использование памяти при последовательных вычислениях. В этом материале рассмотрены последовательный и параллельный блочные алгоритмы перемножение матриц, указаны некоторые их преимущества по сравнению с обычными, точными алгоритмами. Кратко рассматривается так называемый скошенный (косой) параллелизм.

## Блочные матрицы. Операции над блочными матрицами.

Рассмотрим некоторую матрицу A. Разделим матрицу горизонтальными и вертикальными прямыми линии. Получим подматрицы, которые называются блоками матрицы A. Например, если использовать одну вертикальную и одну горизонтальную прямые, то получим разбиение матрицы на четыре блока:

$$A=\begin{pmatrix}a_{1,1} & a_{1,2} & a_{1,3} & a_{1,4} \\ a_{2,1} & a_{2,2} & a_{2,3} & a_{2,4} \\ a_{3,1} & a_{3,2} & a_{3,3} & a_{3,4} \\ a_{4,1} & a_{4,2} & a_{4,3} & a_{4,4}\end{pmatrix}=\begin{pmatrix}\begin{vmatrix}a_{1,1} & a_{1,2} \\ a_{2,1} & a_{2,2}\end{vmatrix} & \begin{vmatrix}a_{1,3} & a_{1,4} \\ a_{2,3} & a_{2,4}\end{vmatrix} \\ \begin{vmatrix}a_{3,1} & a_{3,2} \\ a_{4,1} & a_{4,2}\end{vmatrix} & \begin{vmatrix}a_{3,3} & a_{3,4} \\ a_{4,3} & a_{4,4}\end{vmatrix}\end{pmatrix}=\begin{pmatrix}A_{1,1} & A_{1,2} \\ A_{2,1} & A_{2,2}\end{pmatrix}$$

Очевидно, что умножение блочной матрицы на число, вычитание и сложение матриц с блоками согласованных размеров совершаются по тем же правилам, что и операции над обычными матрицами.

Проиллюстрируем, что и перемножение блочных матриц выполняется таким же образом, как и перемножение обычных матриц. Пусть матрицы A и B имеют две блочные строки, два блочных столбца и блоки произвольного размера r×r. В этом случае порядок матриц равен 2r. Рассмотрим результат перемножения матриц A и B:

$$C=A·B, c_{i,j}=\sum_{k=1}^{2r}a_{i,k}b_{k,j}, 1≤i≤2r, 1≤j≤2r$$

Покажем, что

$$\begin{pmatrix}A_{1,1} & A_{1,2} \\ A_{2,1} & A_{2,2}\end{pmatrix}\begin{pmatrix}B_{1,1} & B_{1,2} \\ B_{2,1} & B_{2,2}\end{pmatrix}=\begin{pmatrix}A_{1,1}B_{1,1}+A_{1,2}B_{2,1} & A_{1,1}B_{1,2}+A_{1,2}B_{2,2} \\ A_{2,1}B_{1,1}+A_{2,2}B_{2,1} & A_{2,1}B_{1,2}+A_{2,2}B_{2,2}\end{pmatrix}$$

Действительно, левая часть есть

$$A·B=\left(\sum_{k=1}^{2r}a_{i,k}b_{k,j}\right)_{i=1,j=1}^{2r,2r}$$

В правой части имеем:

$$\left(\begin{array}{cc}\begin{pmatrix}\sum_{k=1}^{r}a_{i,k}b_{k,j}\end{pmatrix}_{i=1,j=1}^{r,r}+\begin{pmatrix}\sum_{k=r+1}^{2r}a_{i,k}b_{k,j}\end{pmatrix}_{i=1,j=1}^{r,r} & \begin{pmatrix}\sum_{k=1}^{r}a_{i,k}b_{k,j}\end{pmatrix}_{i=1,j=r+1}^{r,2r}+\begin{pmatrix}\sum_{k=r+1}^{2r}a_{i,k}b_{k,j}\end{pmatrix}_{i=1,j=r+1}^{r,2r} \\ \begin{pmatrix}\sum_{k=1}^{2r}a_{i,k}b_{k,j}\end{pmatrix}_{i=r+1,j=1}^{2r,r}+\begin{pmatrix}\sum_{k=r+1}^{2r}a_{i,k}b_{k,j}\end{pmatrix}_{i=r+1,j=1}^{2r,r} & \begin{pmatrix}\sum_{k=1}^{2r}a_{i,k}b_{k,j}\end{pmatrix}_{i=r+1,j=r+1}^{2r,2r}+\begin{pmatrix}\sum_{k=r+1}^{2r}a_{i,k}b_{k,j}\end{pmatrix}_{i=r+1,j=r+1}^{2r,2r}\end{array}\right)$$

$$=\left(\begin{array}{cc}\begin{pmatrix}\left(\sum_{k=1}^{2r}a_{i,k}b_{k,j}\right)_{i=1,j=1}^{r,r}\end{pmatrix} & \begin{pmatrix}\left(\sum_{k=1}^{2r}a_{i,k}b_{k,j}\right)_{i=1,j=r+1}^{r,2r}\end{pmatrix} \\ \begin{pmatrix}\left(\sum_{k=1}^{2r}a_{i,k}b_{k,j}\right)_{i=r+1,j=1}^{2r,r}\end{pmatrix} & \begin{pmatrix}\left(\sum_{k=1}^{2r}a_{i,k}b_{k,j}\right)_{i=r+1,j=r+1}^{2r,2r}\end{pmatrix}\end{array}\right)=\left(\sum_{k=1}^{2r}a_{i,k}b_{k,j}\right)_{i=1,j=1}^{2r,2r}$$


Отметим, что при получении блоков результирующей матрицы суммы имеют вид:
$$A_{i^{gl},1}B_{1,j^{gl}} + A_{i^{gl}+2}B_{2,j^{gl}}$$

где $(i^{gl}, j^{gl})$ — индексы глобальной, т.е. уровня блоков, нумерации. Поэтому произведение матриц в первом слагаемом порождает суммы с пределами суммирования от 1 до r, во втором слагаемом – от r+1 до 2r, пределы изменения i и j в блочных слагаемых совпадают.

Алгоритм перемножение блочных матриц в рассматриваемом случае представим в виде

```
do i^{gl} = 0, 1
  do j^{gl} = 0, 1
    do k^{gl} = 0, 1
      C_{i^{gl}+1,j^{gl}+1} = C_{i^{gl}+1,j^{gl}+1} + A_{i^{gl}+1,k^{gl}+1} · B_{k^{gl}+1,j^{gl}+1}
    enddo
  enddo
enddo
```

Операцию $C_{i^{gl}+1,j^{gl}+1} = C_{i^{gl}+1,j^{gl}+1} + A_{i^{gl}+1,k^{gl}+1} · B_{k^{gl}+1,j^{gl}+1}$ перемножения блоков матриц A и B с суммированием промежуточных результатов (перед началом вычислений массив C обнуляется) можно представить в следующем виде:

```
do i = 1 + i^{gl} r, (i^{gl}+1) r
  do j = 1 + j^{gl} r, (j^{gl}+1) r
    do k = 1 + k^{gl} r, (k^{gl}+1) r
      c(i,j) = c(i,j) + a(i,k) b(k,j)
    enddo
  enddo
enddo
```

Таким образом, на примере матриц с двумя блочными строками и двумя блочными столбцами показано, что операция перемножения блочных матриц выполняется по тем же правилам, что и операция перемножения обычных матриц.

При транспонировании матрицы, разбитой на блоки, транспонированию подлежат как блоки матрицы, так и элементы блоков. Например:

$$A^{T}=\begin{pmatrix}A_{1,1} & A_{1,2} \\ A_{2,1} & A_{2,2}\end{pmatrix}^{T}=\begin{pmatrix}A_{1,1}^{T} & A_{2,1}^{T} \\ A_{1,2}^{T} & A_{2,2}^{T}\end{pmatrix}$$

Действительно, для блоков размера 2×2:

$$A=\begin{pmatrix}a_{1,1} & a_{1,2} & a_{1,3} & a_{1,4} \\ a_{2,1} & a_{2,2} & a_{2,3} & a_{2,4} \\ a_{3,1} & a_{3,2} & a_{3,3} & a_{3,4} \\ a_{4,1} & a_{4,2} & a_{4,3} & a_{4,4}\end{pmatrix}$$

$$\begin{pmatrix}A_{1,1}^{T} & A_{2,1}^{T} \\ A_{1,2}^{T} & A_{2,2}^{T}\end{pmatrix}=\begin{pmatrix}\begin{vmatrix}a_{1,1} & a_{1,2} \\ a_{2,1} & a_{2,2}\end{vmatrix}^{T} & \begin{vmatrix}a_{3,1} & a_{3,2} \\ a_{4,1} & a_{4,2}\end{vmatrix}^{T} \\ \begin{vmatrix}a_{1,3} & a_{1,4} \\ a_{2,3} & a_{2,4}\end{vmatrix}^{T} & \begin{vmatrix}a_{3,3} & a_{3,4} \\ a_{4,3} & a_{4,4}\end{vmatrix}^{T}\end{pmatrix}=\begin{vmatrix}a_{1,1} & a_{2,1} & a_{3,1} & a_{4,1} \\ a_{1,2} & a_{2,2} & a_{3,2} & a_{4,2} \\ a_{1,3} & a_{2,3} & a_{3,3} & a_{4,3} \\ a_{1,4} & a_{2,4} & a_{3,4} & a_{4,4}\end{vmatrix}=A^{T}$$

## Использование блочных алгоритмов в последовательных вычислениях

Время решения задачи на современном компьютере определяется не столько скоростью выполнения вычислительных операций, сколько скоростью доступа к памяти. Скорость доступа существенно зависит от места в иерархической памяти (диск, оперативная память, кэши, регистры), где хранятся данные. Поэтому для быстрой реализации алгоритма, заданного последовательной программой, задача быстрого (до исчезновения из памяти с быстрым доступом) переиспользования данных является одной из важнейших.

Загрузка значений в кэш осуществляется блоками (строками кэша) из последовательно расположенных в памяти элементов массивов (размер строки кэша может быть равен, например, 128 байтам). Кэш будет эффективно использоваться, если в выполняемых друг за другом вычислениях происходит обращение к одним и тем же элементам оперативной памяти или к элементам памяти с последовательно возрастающими адресами. Блок матрицы содержит близко расположенные в памяти элементы массива по строкам (при использовании языка программирования C) или по столбцам (при использовании Фортрана). Поэтому при выполнении блочных вариантов алгоритмов кэш используется эффективно.

Рассмотрим алгоритм перемножения матрицы A размера N₁×N₃ и матрицы B размера N₃×N₂:

```
do i = 1, N₁
  do j = 1, N₂
    c(i,j) = 0
    do k = 1, N3
      c(i,j) = c(i,j) + a(i,k) b(k,j)  
    enddo
  enddo
enddo
```

Пусть хранение элементов массивов осуществляется по строкам. При выполнении алгоритма используются N₃ раза элементы массива b(k,j), расположенные в памяти на расстоянии друг от друга N₂ ячеек. Если N₃ и N₂ являются достаточно большими числами, то обращение к элементу массива b(k,j), перенесенному ранее в кэш в составе строки кэша (т.е. в составе последовательно расположенных в памяти элементов массива), произойдет уже после того, как он будет «вытеснен» из кэша другими данными. Таким образом, при больших значениях N₃ и N₂ обращение к близко расположенным в памяти элементам массива происходит через значительное число итераций и неизбежны кэш-промахи.

Блок матрицы имеет сравнительно небольшие размеры, внутренние циклы блочных алгоритмов выполняют сравнительно (с размером задачи) небольшое число итераций. Поэтому при выполнении блочных вариантов алгоритмов кэш используется эффективно: гораздо чаще происходит обращение к близко расположенным в памяти элементам массива (причем независимо от того, по строкам или по столбцам они расположены в памяти).

Обозначим Q₁ = ⌈N₁/r⌉, Q₂ = ⌈N₂/r⌉, Q₃ = ⌈N₃/r⌉. Будем предполагать для простоты записи пределов изменения числа блоков, что Q₁, Q₂, Q₃ являются целыми; иначе потребовалось бы использовать обозначение ближайшего «сверху» целого числа: ⌈N₁/r⌉, ⌈N₂/r⌉, ⌈N₃/r⌉. Числа Q₁, Q₂, Q₃ задают количество блочных строк и столбцов матриц A, B и C. Например, Q₁ задает количество блочных строк матриц A и C.

Рассмотрим алгоритм перемножения блочных матриц с блоками размера r×r. Перед началом вычислений массив C обнуляется. Операции, как и в рассмотренном ранее частном случае, объединены в макрооперации. Алгоритм уровня макроопераций имеет следующий вид:

```
do i^{gl} = 0, Q₁ - 1
  do j^{gl} = 0, Q₂ - 1
    do k^{gl} = 0, Q₃ - 1
      C_{i^{gl}+1,j^{gl}+1} = C_{i^{gl}+1,j^{gl}+1} + A_{i^{gl}+1,k^{gl}+1} · B_{k^{gl}+1,j^{gl}+1}
    enddo
  enddo
enddo
```

Блочные алгоритмы являются двухуровневыми: на первом (глобальном) уровне выполняются блочные операции, на втором (локальном) уровне выполняются обычные операции. Одной макрооперацией $C_{i^{gl}+1,j^{gl}+1} = C_{i^{gl}+1,j^{gl}+1} + A_{i^{gl}+1,k^{gl}+1} · B_{k^{gl}+1,j^{gl}+1}$   является перемножение блоков матриц A и B с суммированием промежуточных результатов:

```
do i = 1 + i^{gl} r, (i^{gl}+1) r
  do j = 1 + j^{gl} r, (j^{gl}+1) r
    do k = 1 + k^{gl} r, (k^{gl}+1) r
      c(i,j) = c(i,j) + a(i,k) b(k,j)
    enddo
  enddo
enddo
```

Фактически реализуется следующий алгоритм:

```
do i = 1, N₁
  do j = 1, N₂
    c(i,j) = 0
  enddo
enddo
do i^{gl} = 0, Q₁ - 1
  do j^{gl} = 0, Q₂ - 1
    do k^{gl} = 0, Q₃ - 1
      do i = 1 + i^{gl} r, (i^{gl}+1) r
        do j = 1 + j^{gl} r, (j^{gl}+1) r
          do k = 1 + k^{gl} r, (k^{gl}+1) r
            c(i,j) = c(i,j) + a(i,k) b(k,j)                    (2)
          enddo
        enddo
      enddo
    enddo
  enddo
enddo(k^{gl})
enddo(j^{gl})
enddo(i^{gl})
```

При проведении экспериментов вычисления надо оптимизировать. Например: $ai=i^{gl}r, aileft=i^{gl}r+1, airight=i^{gl}r+r$ вычислить один раз (сразу после do i^{gl}=0,Q₁-1), а не вычислять многократно $1+i^{gl}r, (i^{gl}+1)r$

# Параллельные блочные алгоритмы для реализации на многоядерном CPU

В рассмотренном алгоритме перемножения матриц вычисление всех элементов массива c(i,j) можно проводить параллельно, независимо друг от друга. Фактически независимо вычисляются суммы $c_{i,j}=\sum_{k=1}^{N_1} a_{i,k} b_{k,j}$, $1 \leq i \leq N_1$, $1 \leq j \leq N_2$ (циклы, итерации которых заведомо можно выполнять независимо, записием как dopar):

```
dopar i = 1, N₁ // Запись в виде dopar означает возможность, но не
обязательность, независимого выполнения итераций цикла
dopar j = 1, N₂
    c(i,j) = 0
    do k = 1, N₃
        c(i,j) = c(i,j) + a(i,k)·b(k,j)
    enddo
endopar
endopar
```

Этот алгоритм можно использовать для OpenMP-реализаций на многоядерных компьютерах. Одновременное выполнение операций потоками вычислений позволяет добиться ускорения вычислений на многоядерном процессоре.

Можно также использовать блочный алгоритм, параллельность внешних циклов сохраняется.

Использование для организации параллельных потоков циклов с параметром $i^{gl}$:

```
do i = 1, N₁
    do j = 1, N₂
        c(i,j) = 0
    enddo
enddo
// Итерации следующего цикла распределяются между потоками
#pragma omp parallel for num_threads(4)
dopar i^gl = 0, Q₁-1
    do j^gl = 0, Q₂-1
        do k^gl = 0, Q₃-1
            do i = 1+ i^gl·r, (i^gl+1)r
                do j = 1+ j^gl·r, (j^gl+1)r
                    do k = 1+ k^gl·r, (k^gl+1)r
                        c(i,j) = c(i,j) + a(i,k)·b(k,j)                    (3)
                    enddo 
                enddo
            enddo
        enddo(k^gl)
    enddo(j^gl)
endopar(i^gl)
```

Использование для организации параллельных потоков циклов с параметром $j^{gl}$:

```
do i = 1, N₁
    do j = 1, N₂
        c(i,j) = 0
    enddo
enddo
do i^gl = 0, Q₁-1
    // Итерации следующего цикла распределяются между потоками
    #pragma omp parallel for num_threads(4)
    dopar j^gl = 0, Q₂-1
        do k^gl = 0, Q₃-1
            do i = 1+ i^gl·r, (i^gl+1)r
                do j = 1+ j^gl·r, (j^gl+1)r
                    do k = 1+ k^gl·r, (k^gl+1)r
                        c(i,j) = c(i,j) + a(i,k)·b(k,j)                    (4)
                    enddo
                enddo
            enddo
        enddo(k^gl)
    endopar(j^gl)
    enddo(i^gl)
```

Использование для организации параллельных потоков циклов с параметром $i^{gl}$ и с параметром $j^{gl}$:

```
do i = 1, N₁
    do j = 1, N₂
        c(i,j) = 0
    enddo
enddo
// Итерации следующих двух циклов распределяются между потоками
#pragma omp parallel for num_threads(4) collapse(2)
dopar i^gl = 0, Q₁-1
    dopar j^gl = 0, Q₂-1
        do k^gl = 0, Q₃-1
            do i = 1+ i^gl·r, (i^gl+1)r
            do j = 1+ j^gl·r, (j^gl+1)r
            do k = 1+ k^gl·r, (k^gl+1)r
                c(i,j) = c(i,j) + a(i,k)·b(k,j)                    (5)
            enddo
        enddo
    enddo
    enddo(k^gl)
endopar(j^gl)
endopar(i^gl)
```

Как и в случае последовательных алгоритмов, при выполнении блочных вариантов эффективно используется кэш. С ростом числа используемых ядер преимущество параллельного алгоритма по сравнению с последовательным алгоритмом увеличивается, так как помимо общей для всех ядер кэш-памяти каждое ядро имеет свою кэш-память. Суммарно размер кэша становится больше.

# Скошенный параллелизм

Сделаем еще замечание о так называемом скошенном (косом) параллелизме.

Пусть в алгоритме вида

```
do i^gl = 0, Q₁ -1
    do j^gl = 0, Q₂ -1
        Bl(i^gl, j^gl)
    enddo
enddo
```

циклы не являются параллельными. Тогда часто на практике можно одновременно и независимо выполнять итерации (i^gl, j^gl) такие, что i^gl + j^gl = t, где t является фиксированным числом:

```
do t=0, Q₁ + Q₂ -2
    dopar i^gl = 0, Q₁ -1
        dopar j^gl = 0, Q₂ -1
            if i^gl + j^gl = t then
                Bl(i^gl, j^gl)
            enddopar
        enddopar
    enddo
```

Алгоритм с явно заданным параллелизмом можно представить еще в следующем виде:

```
do t=0, Q₁ + Q₂ -2
    dopar i^gl = max(0, t - Q₁ +1), min(t, Q₂ -1)
        i^gl = t - j^gl
        Bl(i^gl, j^gl)
    enddopar
enddo
```

Такая запись является следствием аффинного преобразования t = i^gl + j^gl, j^gl_new = j^gl_old исходного алгоритма

```
do i^gl = 0, Q₁ -1
    do j^gl = 0, Q₂ -1
        Bl(i^gl, j^gl)
    enddo
enddo
```

Обоснуем указанный конструктивный способ выделения параллелизма.

**Определение.** Итерация (i_in, j_in) зависит от итерации (i_out, j_out), если некоторое данное, вычисленное на итерации (i_out, j_out), используется на итерации (i_in, j_in).

**Утверждение 1.** Пусть имеется функция t₁(i,j) такая, что для любой пары зависимых итераций (i_out, j_out) и (i_in, j_in) справедливо t₁(i_in, j_in) > t₁(i_out, j_out). Тогда можно одновременно и независимо выполнять итерации (i,j), для которых функция t₁(i,j) принимает одно и то же значение.

Действительно, если выполняется условие утверждения 1, то среди итераций с одинаковым значением функции t₁(i,j)=t не может быть зависимых: для любых двух зависимых итераций (i₁,j₁) и (i₂,j₂) имеет место либо t₁(i₁,j₁)>t₁(i₂,j₂), либо t₁(i₂,j₂)>t₁(i₁,j₁).

**Утверждение 2.** Если для любой пары зависимых итераций (i_out, j_out) и (i_in, j_in) справедливо i_in ≥ i_out, j_in ≥ j_out то можно одновременно и независимо выполнять итерации (i,j) такие, что i+j=t, где t есть фиксированное число.

Утверждение 2 является следствием утверждения 1, если рассмотреть t₁(i,j)=i+j: так как i_in ≥ i_out, j_in ≥ j_out, (i_out, j_out) ≠ (i_in, j_in), то t₁(i_in, j_in) = i_in + j_in ≥ i_out + j_out = t₁(i_out, j_out).

**Замечание.** В действительности следует учитывать еще так называемые ложные зависимости: изменение порядка выполнения операций должно сохранять корректное использование ячеек памяти.