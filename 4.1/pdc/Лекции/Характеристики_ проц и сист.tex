 \documentclass[12pt]{article}
 \usepackage[cp1251]{inputenc}
 \usepackage[russian]{babel}
 \usepackage{graphicx}
 \usepackage{amsfonts,amssymb,eucal,amsmath}

\textwidth 170 mm
\textheight 255 mm
\begin{document}
\voffset = -3.0 cm
\hoffset = -1.5 cm
\parindent = 35pt
\baselineskip 18pt
\sloppy
%\pagestyle{empty}


\newcommand{\msum}{\mathop{\sum}\limits}
\newcommand{\bN}{{\rm{\bf N}}}
\newcommand{\bZ}{{\rm{\bf Z}}}
\newcommand{\bQ}{{\rm{\bf Q}}}
\newcommand{\m}{\mathop{\rm mod}\nolimits M}
\newcommand{\rmod}{\mathop{\rm mod}\nolimits}
\newcommand{\nmod}[1]{\; {\mathop{\rm mod \;}\nolimits} #1}
\newcommand{\ndiv}[1]{\; {\mathop{\rm div \;}\nolimits} #1}
\newcommand{\rmin}{\mathop{\rm min}\limits}
\newcommand{\rmax}{\mathop{\rm max}\limits}
\newcommand{\rlog}{\mathop{\rm log}\nolimits}
\newcommand{\rlg}{\mathop{\rm lg}\nolimits}
\newcommand{\rln}{\mathop{\rm ln}\nolimits}
\newcommand{\Z}{{\rm {\bf Z}}}
\newcommand{\N}{{\rm {\bf N}}}
\newcommand{\R}{{\rm {\bf R}}}
\newcommand{\0}{{\rm {\bf 0}}}
\newfont{\wncyr}{wncyr10}



\large
%\normalsize



 \centerline{\bf ХАРАКТЕРИСТИКИ ПАРАЛЛЕЛЬНЫХ}
 \centerline{\bf  ВЫЧИСЛИТЕЛЬНЫХ ПРОЦЕССОВ И СИСТЕМ}



\bigskip

 Характеристики, связанные с работой вычислительной системы, ---
 производительность, загруженность,
 ускорение --- позволяют оценить
 качество процессов работы, находить и устранять узкие
 места.

 Пусть вычислительная система состоит
 из $s$ процессоров\footnote{Под процессором понимается одно вычислительное ядро.}
  с пиковыми производительностями $\pi_1,\ldots
 ,\pi_s$.

 Будем рассматривать характеристики в рамках
 абстрактной модели функционирования вычислительной системы:
 все операции алгоритма обеспечены необходимыми для срабатывания
 данными  и одинаковы по длительности выполнения.
 Чтобы не загромождать формулы и выкладки,
 число выполняемых в единицу времени операций будем считать целым.

 \textbf{Утверждение 1}.
 {\em  Если процессоры работают с загруженностями $p_1,\ldots
 ,p_s$, то реальная производительность $r$ системы выражается формулой
 \begin{equation}
  r=\msum_{i=1}^s  p_i \pi_i.
 \label{r}
 \end{equation}
}

 \textbf{Доказательство.}
 Реальная производительность системы равна
 сумме  реальных производительностей
 всех процессоров.
 Пусть за время $T$ процессор с пиковой производительностью $\pi_i$ выполнил $N_i$ операций.
 Тогда время реальной работы процессора равно $\dfrac{N_i}{\pi_i}$,
 а загруженность процессора равна
  $p_i=\dfrac{N_i/\pi_i}{T}$.
 Количество операций, реально выполняемых системой за единицу
 времени:

$ r=\msum_{i=1}^s  r_i =
  \msum_{i=1}^s \dfrac{N_i}{T}=
 \msum_{i=1}^s
 \dfrac{N_i/\pi_i}{T} \pi_i
 =\msum_{i=1}^s  p_i \pi_i.$
 $\hfill\Box$

 Из равенства $r=p \pi$ для одного процессора следует, что для повышения
 производительности надо увеличивать загруженность процессора
 (что вполне логично). Желательно определение загруженности
  вычислительной системы
 ввести таким образом, чтобы равенство $r=p \pi$ также выполнялось.

  Определим загруженность системы как взвешенную сумму загруженностей
 отдельных процессоров:\\
 \centerline{
 $p=\msum_{i=1}^s \alpha_i p_i$, \ \ \
  $\alpha_i = \dfrac{\pi_i}{\msum_{j=1}^s \pi_j}$.}
 Такое определение согласуется с ранее введенными понятиями:
 если система состоит из одного
  процессора ($s = 1$), то понятия загруженности системы и
  процессора совпадают; загруженность системы,
 состоящей из одинаковых процессоров \Big($\alpha_i = \dfrac{1}{s}$\Big) --- среднее арифметическое
 загруженностей всех процессоров;
 $0\le p \le 1,$ причем загруженность системы равна 1 ($p = 1$)
  тогда и только тогда, когда равны 1 загруженности каждого
  процессора ($p_i = 1$).

 \textbf{Утверждение 2}.
 {\em  Реальная производительность системы с пиковой производительностью
 $\pi$ выражается формулой
 \begin{equation}
  r=p \pi .
 \label{rp}
 \end{equation}
}
 \par \textbf{Доказательство.}
 Так как $\pi = \msum_{j=1}^s \pi_j$ (пиковая производительность системы равна
 сумме пиковых производительностей
 всех процессоров), то
\\
 $r=\msum_{i=1}^s  p_i \pi_i
 =\pi \msum_{i=1}^s  p_i \frac{\pi_i}{\msum_{j=1}^s \pi_j}
  =\pi \msum_{i=1}^s  p_i \alpha_i = \pi p.$
$\hfill\Box$

 Таким образом, для достижения наибольшей реальной
 производительности вычислительной системы нужно обеспечить
 наибольшую ее загруженность. Для практических целей понятие
 производительности является наиболее важным, так как показывает,
 насколько эффективно система выполняет полезную работу.
 Понятие загруженности полезно тем, что указывает путь
 повышения производительности.

 Обозначим через $\pi_{max}$ наибольшую , а через $\pi_{min}$ наименьшую из величин
 $\pi_1,\ldots ,\pi_s$.

 Определим ускорение $R$ реализации алгоритма на данной вычислительной системе:
  \begin{equation}
 R=\dfrac{r}{\pi_{max}}.
   \label{Rdef}
 \end{equation}
 $R$ показывает, во сколько раз количество операций, реально выполняемых
 системой за единицу
 времени, превосходит количество операций, которое может быть выполнено
  за единицу времени одним самым мощным процессором системы.
 Это определение равносильно определению
 $$R=\dfrac{T_{min}}{T},$$
 где $T_{min}$ --- время выполнения алгоритма
 одним  полностью загруженным процессором
 с пиковой производительностью $\pi_{max},$
  $T$ --- время выполнения алгоритма системой\footnote{На практике
   используется формула $R=\dfrac{T_{real}}{T}$,
   где $T_{real}$ --- фактическое время выполнения алгоритма
 одним  процессором.}. Действительно,
 если $N$ --- число операций алгоритма, то
 $\dfrac{T_{min}}{T}=\dfrac{N/\pi_{max}}{N/r}=\dfrac{r}{\pi_{max}}.$

 Из определения ускорения $R=\dfrac{r}{\pi_{max}}$ и формулы (\ref{r}) $r=\msum_{i=1}^s  p_i \pi_i$ имеем
 \begin{equation}
  R=\dfrac{\msum_{i=1}^s  p_i \pi_i}{\pi_{max}}.
   \label{R}
 \end{equation}
 В частности, если все процессоры
 имеют одинаковые пиковые производительности, то
 \begin{equation}
  R=\msum_{i=1}^s  p_i .
   \label{Rs}
 \end{equation}
 Формула (\ref{R}) показывает, что ускорение системы, состоящей из $s$
 процессоров, не превосходит $s$, и может достигать $s$
 только в том случае, когда все процессоры
 имеют одинаковые пиковые производительности и полностью
 загружены.

 С помощью формулы (\ref{Rs}) можно установить равносильность
 понятий загруженности и эффективности вычислительной
 системы, состоящей из $s$ одинаковых процессоров.
 Для этого достаточно сравнить определения:
 загруженность --- среднее арифметическое
 загруженностей всех процессоров,
 эффективность --- отношение ускорения
 (равного по формуле (\ref{Rs}) сумме загруженностей) к $s$.

 Сделаем еще следующее замечание. В формуле $R=\dfrac{T_{min}}{T}$
величина $T_{min}=N/\pi_{max}$ --- это время выполнения алгоритма
 одним  полностью загруженным процессором
 Pr$_{max}$ с теоретической производительностью $\pi_{max}$.
 Это время меньше реального времени выполнения алгоритма
 одним процессором, так как
 процессор не может быть полностью загружен хотя бы
 из-за необходимости обращения к иерархической памяти.
 В то же время, загруженность процессоров системы
 может быть больше реальной загруженности
 процессора Pr$_{max}$ (выполняющего последовательную версию алгоритма), если обменов мало, а
 работа с иерархической памятью получилась более эффективной.
  Предпосылками такой работы являются
 увеличение суммарной распределенной памяти и уменьшение
 размера массивов, необходимых одному процессору.
 Поэтому ускорение может быть суперлинейным и быть больше $s$,
 если вместо $T_{min}$ при определении ускорения
 использовать реальное время выполнения алгоритма
 и определять ускорение как $R=\dfrac{T_{real}}{T}$ --- отношение
 времени выполнения алгоритма на одном процессоре к времени
 параллельного выполнения.

  \textbf{Утверждение 3}.
 {\em Если вычислительная система состоит из $s$
  связанных между собой процессоров
  с пиковыми производительностями
  $\pi_1,\ldots ,\pi_s$,
 то в общем случае
\begin{itemize}
\item
 производительность системы не превосходит
 \begin{equation}
  r^{max}=s \pi_{min} ,
 \label{rmax}
 \end{equation}
\item
 загруженность системы не превосходит
 \begin{equation}
  p^{max}=\dfrac{s \pi_{min}}{\msum_{j=1}^s \pi_j},
 \label{pmax}
 \end{equation}
\item
 ускорение системы не превосходит
 \begin{equation}
  R^{max}=\dfrac{s \pi_{min}}{\pi_{max}}.
 \label{Rmax}
 \end{equation}
\end{itemize}
}

  \textbf{Доказательство.}
  Пусть процессор Pr$_i$ за время $T$ выполняет $N_i$ операций,
  процессор Pr$_j$ выполняет $N_j$ операций,
  и каждый результат процессора Pr$_i$ является одним из
  аргументов очередного срабатывания процессора Pr$_j$.
  Тогда количество операций, реализованных процессором
   Pr$_j$ за время $T$, не может более, чем на 1 отличаться
 от количества операций, реализованных процессором
   Pr$_i,$ т.е. $N_i-1 \le N_j \le N_i+1.$
 Аналогично, для любых процессоров Pr$_k$ и
   Pr$_l$,  $1 \le k,l \le s$, связанных опосредовано,
   выполняется $N_l-q \le N_k \le N_l+q,$ где
 $q$ --- число соединений между процессорами системы.

 Имеем:\\
 \centerline{$ r=\msum_{i=1}^s  r_i
 =\dfrac{N_1}{T} + \msum_{i=2}^s
 \dfrac{N_i}{T},$}\\
 \centerline{$\dfrac{N_1}{T} + \msum_{i=2}^s \dfrac{N_1-q}{T}
 \le r \le
 \dfrac{N_1}{T} + \msum_{i=2}^s \dfrac{N_1+q}{T},$}
 \\
 \centerline{$\dfrac{N_1 s}{T} - \dfrac{q(s-1)}{T}
 \le r \le
 \dfrac{N_1 s}{T} + \dfrac{q(s-1)}{T}.$}\\
 Так как $\dfrac{q(s-1)}{T}$ стремится к нулю
 при $T,$ стремящимся к бесконечности,
 то асимптотически $r=\dfrac{N_1 s}{T}$.
 Асимптотически все $N_k$ равны между собой;
 кроме того, всегда выполняется неравенство
 $N_k\le \pi_k T$. Поэтому асимптотически
  $N_{1} \le \pi_{min} T$, а
 максимально возможная реальная производительность равна
 $\pi_{min} s.$ Справедливость формулы (\ref{rmax}) доказана.

 Справедливость формулы (\ref{pmax})
 $p^{max}=\dfrac{s \pi_{min}}{\msum_{j=1}^s \pi_j}$
 непосредственно следует из формул
 (\ref{rp}) $r=p \pi$, (\ref{rmax}) $r^{max}=s \pi_{min}$,
 а справедливость формулы (\ref{Rmax})
 $R^{max}=\dfrac{s \pi_{min}}{\pi_{max}}$
 непосредственно следует из формул
  (\ref{Rdef}) $R=\dfrac{r}{\pi_{max}}$, (\ref{rmax}) $r^{max}=s \pi_{min}$.
 $\hfill\Box$

 Из доказательства утверждения следует, что
 для системы связанных процессоров
 \begin{itemize}
 \item
 асимптотически каждый процессор выполняет одно и то же число
 операций.
 \end{itemize}
 Поэтому:
 \begin{itemize}
 \item
 загруженность любого процессора не превосходит загруженности
 самого непроизводительного процессора,
 \item
 если загруженность какого-то процессора равна 1, то это
 самый непроизводительный процессор.
 \end{itemize}

 Еще одно следствие утверждения 3 является именным:

 \textbf{Первый закон Амдала}.
 {\em
 Производительность многопроцессорной
 вычислительной системы определяется в общем случае
 самым непроизводительным процессором.
 }


 Далее исследуем, как выражается
 ускорение системы, если часть операций алгоритма
 выполняется последовательно.

 Предположим, что $n$ из $N$ операций алгоритма
 выполняются системой последовательно.
 Отношение $\beta = n/N$ называется долей последовательных
 вычислений.

 \textbf{Второй закон Амдала}.
 {\em Пусть система состоит из $s$ одинаковых процессоров.
 Если при вычислении параллельной части алгоритма все процессоры
 загружены полностью, то ускорение выражается формулой
 \begin{equation}
R=\dfrac{s}{\beta s+ (1-\beta)}.
   \label{Ad2}
 \end{equation}
}

  \vspace{-5mm}
\textbf{Доказательство.}
 Воспользуемся формулой (\ref{Rs}) $R=\msum_{i=1}^s  p_i$.
 Пусть всего выполняется $N$ операций.
 Не ограничивая общности можно считать, что
 последовательные $\beta N$ операций выполняются на первом
 процессоре, и $N-\beta N$ операций выполняется
 параллельно на $s$ процессорах
 по $(1-\beta)N/s$ операций на каждом. Ясно, что $p_1=1.$
 Найдем остальные $p_i.$

 Всего алгоритм реализуется за время
 $T_1=\dfrac{\beta N +(1-\beta)N/s}{\pi_1}.$
 Параллельная часть алгоритма реализуется за время
  $T_i=\dfrac{(1-\beta)N/s}{\pi_i}.$
 В выражениях $T_1$ и $T_i$ учтено, что при вычислении параллельной части алгоритма все процессоры
 загружены полностью.
 Так как все процессоры имеют одинаковые пиковые
 производительности, то

  $p_i=\dfrac{T_i}{T_1}=\dfrac{(1-\beta)N/s}{\beta N
  +(1-\beta)N/s}=\dfrac{1-\beta}{\beta s
  +(1-\beta)}.$\\
 Следовательно,\\
 $R=1+\msum_{i=2}^s  p_i
 = 1+\msum_{i=2}^s\dfrac{1-\beta}{\beta s
  +(1-\beta)}
= 1+\dfrac{(1-\beta)(s-1)}{\beta s
  +(1-\beta)}
  =\dfrac{s}{\beta s+ (1-\beta)}.$
 $\hfill\Box$
 \\

Прямым следствием второго закона Амдала является следующее очень
важное утверждение.

 \textbf{Третий закон Амдала}.
 {\em
 Пусть вычислительная система состоит из
 одинаковых процессоров. При любом режиме работы
 ее ускорение не может превзойти обратной величины доли
 последовательных вычислений.
 }

 Например, если доля последовательных вычислений
 составляет всего 1\%, то ни при каком числе процессоров
 нельзя добиться ускорения более чем в 100 раз.
 Если вычислительная система состоит из
 тысяч процессоров, то для эффективного ее использования
 доля последовательных вычислений должна быть
 порядка десятых и сотых долей процента.

 Теперь исследуем, как изменится  формула (\ref{Ad2}), если учитывать затраты времени
 на коммуникационные операции (между вычислительными процессами).
 Введем в рассмотрение величины $c_{alg} = N_{comm}/N$ и  $c_{dev}= t_{comm}/\tau$,
 где $N_{comm}$ -- число коммуникационных операций
 алгоритма,  $t_{comm}$ -- время выполнения одной коммуникационной
 операции,  $\tau$ -- время выполнения одной вычислительной
 операции. Величина $c_{alg}$ определяется алгоритмом,
 а величина  $c_{dev}$ -- техническими характеристиками вычислительной
 системы и способом реализации коммуникационных операций.

 \textbf{Сетевой закон Амдала}.
 {\em Пусть система состоит из $s$ одинаковых процессоров.
 Если при вычислении параллельной части алгоритма все процессоры
 загружены полностью, то ускорение выражается формулой
 \begin{equation}
R=\dfrac{s}{\beta s+ (1-\beta) + c_{alg} c_{dev} s}.
   \label{NAmd}
 \end{equation}
}

  \vspace{-5mm}
\textbf{Доказательство.}
  Пусть
  $T$ -- время реализации алгоритма на одном процессоре
  (тогда $T=N \tau$).
  Из формулы (\ref{Ad2}) $R=\dfrac{s}{\beta s+ (1-\beta)}$, записанной в виде $R=\dfrac{T}{(\beta + (1-\beta)/s)T}$,
  следует, что $(\beta + (1-\beta)/s)T$ есть время параллельной
  реализации алгоритма без учета затрат на коммуникационные
  операции.
  Тогда время параллельной
  реализации алгоритма с учетом затрат на коммуникационные
  операции равно $(\beta + (1-\beta)/s)T + N_{comm} t_{comm}$.
  В этом случае
  $$R=\dfrac{T}{(\beta + (1-\beta)/s)T+ N_{comm} t_{comm}}
  =\dfrac{1}{(\beta + (1-\beta)/s)+ (N_{comm} t_{comm})/T}=$$
  $$\dfrac{s}{\beta  s + (1-\beta)+ s(N_{comm} t_{comm})/(N \tau)}
  =\dfrac{s}{\beta s+ (1-\beta) + c_{alg} c_{dev}s}.$$
 $\hfill\Box$

 Из формулы (\ref{NAmd}) следует

  \textbf{Сетевой аналог третьего закона Амдала}.
 {\em Ускорение не может превзойти величины
 \begin{equation*}
\dfrac{1}{\beta +  c_{alg} c_{dev}},
   \end{equation*}
 где $\beta$ -- доля последовательных вычислений алгоритма,
 $c_{alg}$ -- отношение числа всех коммуникационных операций алгоритма
 к числу всех вычислительных операций алгоритма,
$c_{dev}$ -- отношение времени выполнения одной коммуникационной операции
 к времени выполнения одной вычислительной операции.}

 Основной ресурс увеличения ускорения при организации распределенных вычислений алгоритма --
 уменьшение числа коммуникационных операций.

 Получим еще одно представление ускорения.
 Обозначим через $\beta_{T}$ долю времени последовательных
 вычислений при условии, что параллельная часть полностью занимает
 $s$ одинаковых процессоров. Не следует путать  долю времени последовательных
 вычислений $\beta_{T}$ (это величина по определению зависит от числа
 $s$ используемых процессоров) и долю последовательных
 вычислений $\beta$ (это величина по определению не зависит от числа
 используемых процессоров).

 \textbf{Закон Густавсона-Барсиса}.
 {\em Пусть система состоит из $s$ одинаковых процессоров.
 Если при вычислении параллельной части алгоритма все процессоры
 загружены полностью, то ускорение выражается формулой
 \begin{equation}
R=s-(s-1)\beta_{T}.
   \label{GB}
 \end{equation}
}

\vspace{-5mm}
  \textbf{Доказательство.}
 Пусть, как и ранее, всего выполняется $N$ операций,
 $n$ операций выполняются в последовательной части,
 $\beta = n/N$ -- доля последовательных
 вычислений, последовательные $\beta N$ операций выполняются на первом
 процессоре, $N-\beta N$ операций выполняется
 параллельно на $s$ процессорах.

  Всего алгоритм реализуется за время
 $T_1=\dfrac{\beta N +(1-\beta)N/s}{\pi_1}.$
 Последовательная часть алгоритма реализуется за время
  $\dfrac{\beta N}{\pi_1}.$
 Доля времени последовательных
 вычислений:
  $\beta_{T}=\dfrac{\beta N}{\beta N
  +(1-\beta)N/s}=\dfrac{\beta s}{\beta s
  +(1-\beta)}.$

  Отсюда вытекает соотношение, выражающее связь между
  $\beta$ и $\beta_{T}$:\\
   \centerline{$\beta = \dfrac{\beta_{T}}{s-(s-1)\beta_{T}}$.}
   Подставив полученное представление $\beta$ в формулу Амдала
 (\ref{Ad2}) $R=\dfrac{s}{\beta s+ (1-\beta)}$, получим формулу Густавсона-Барсиса (\ref{GB}).
 $\hfill\Box$

 Отметим принципиальное отличие случаев применения формул
 (\ref{Ad2})
 \begin{equation*}
R=\dfrac{s}{\beta s+ (1-\beta)}.
  % \label{Ad2}
 \end{equation*}
  и (\ref{GB})
  \begin{equation*}
R=s-(s-1)\beta_{T}.
 %  \label{GB}
 \end{equation*}
  Формула Амдала применяется для
 прогноза возможного ускорения. При этом величину $\beta$ можно
 подсчитать, не пропуская программу на параллельном компьютере (или вообще не пропуская программу ни на каком компьютере).
 Формула Густавсона-Барсиса применяется для
 оценивания достигнутого ускорения, не пропуская программу на одном процессоре.
 При этом величину $\beta_T$ можно
 подсчитать в процессе решения задачи на параллельном компьютере.

 % Далее использована статья
 % Воеводин Вл.В. Top 500: числом или уменьем? //
% Открытые системы. 2005, N10, С.12-15.

% \newpage

\bigskip


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Литература

%{\small

\begin{center}\textbf{Список использованных источников}\end{center}

 1.  Воеводин В. В., Воеводин Вл. В. Параллельные вычисления. --
  СПб.: БХВ-Петербург, 2002. -- 608 с.

 2. Воеводин В. В. Вычислительная математика и структура алгоритмов. --
  Москва: МГУ, 2006. -- 112 с.\ \
  http://parallel.ru/info/parallel/voevodin/

  3. Шпаковский Г.И., Верхотуров А.Е., Серикова Н.В. Руководство по работе на вычислительном кластере. -- Минск: БГУ, 2004. -- 171 с.

 % 3. Воеводин Вл. В. Top 500: числом или умением? //
 %Открытые системы. 2005, \No 10, С.~12-15.

 %4. Воеводин Вл.В. Решение больших задач в распределенных вычислительных
 % средах. //Автоматика и Телемеханика. 2007, N5, С. 32-45.

%}

\end{document}
