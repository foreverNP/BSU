 \documentclass[12pt]{article}
 \usepackage[cp1251]{inputenc}
 \usepackage[russian]{babel}
 \usepackage{graphicx}
 \usepackage{amsfonts,amssymb,eucal,amsmath}

\textwidth 170 mm
\textheight 255 mm
\begin{document}
\voffset = -3.0 cm
\hoffset = -1.5 cm
\parindent = 35pt
\baselineskip 18pt
\sloppy
%\pagestyle{empty}


\newcommand{\msum}{\mathop{\sum}\limits}
\newcommand{\bN}{{\rm{\bf N}}}
\newcommand{\bZ}{{\rm{\bf Z}}}
\newcommand{\bQ}{{\rm{\bf Q}}}
\newcommand{\m}{\mathop{\rm mod}\nolimits M}
\newcommand{\rmod}{\mathop{\rm mod}\nolimits}
\newcommand{\nmod}[1]{\; {\mathop{\rm mod \;}\nolimits} #1}
\newcommand{\ndiv}[1]{\; {\mathop{\rm div \;}\nolimits} #1}
\newcommand{\rmin}{\mathop{\rm min}\limits}
\newcommand{\rmax}{\mathop{\rm max}\limits}
\newcommand{\rlog}{\mathop{\rm log}\nolimits}
\newcommand{\rlg}{\mathop{\rm lg}\nolimits}
\newcommand{\rln}{\mathop{\rm ln}\nolimits}
\newcommand{\Z}{{\rm {\bf Z}}}
\newcommand{\N}{{\rm {\bf N}}}
\newcommand{\R}{{\rm {\bf R}}}
\newcommand{\0}{{\rm {\bf 0}}}
\newfont{\wncyr}{wncyr10}



\large
%\normalsize



\centerline{\bf ЗАДАЧИ СТАТИЧЕСКОГО РАСПАРАЛЛЕЛИВАНИЯ}
\centerline{\bf ПОСЛЕДОВАТЕЛЬНЫХ ПРОГРАММ}

%\medskip

 (Основные задачи статического распараллеливания,
 возникающие при отображении алгоритмов,
 задаваемых последовательными программами,
 на параллельные компьютеры с распределенной памятью)

\medskip

    Будем в качестве целевого суперкомпьютера\footnote{Целевой суперкомпьютер --- это
 компьютер, на котором требуется реализовать
 параллельную версию алгоритма.}
 рассматривать многопроцессорный компьютер
 с распределенной памятью. К компьютерам с распределенной памятью
 относятся, в частности,
 мультикомпьютерные вычислительные системы
 типа белорусско-российского суперкомпьютера СКИФ.
 Во многом мы будет также ориентироваться на многоядерные
 персональные компьютеры и на графические процессоры.

 На практике параллельные алгоритмы  получают
 преобразованием разработанных ранее последовательных алгоритмов.
 Новые оригинальные параллельные алгоритмы, за исключением
 процесса сдваивания и алгоритма параллельной матричной прогонки, оказались не пригодными
 для практического использования.
 Они требуют слишком большого числа процессоров,
 очень много памяти, труднореализуемые коммуникации.

 Даже математически эквивалентные последовательные алгоритмы могут иметь разные
 вычислительные свойства, в том числе и разные параллельные
 свойства. Но алгоритмов разработано очень много.
 Из них, как правило, можно выбрать подходящий для распараллеливания.

 Будем считать, что алгоритм задан последовательной программой.
 Такое представление позволяет точно изложить содержание
 математической записи алгоритма, не оставляет неопределенности
 в отношении порядка выполнения операций.
 Будем также считать, что рассматриваемые программы и фрагменты программ
 принадлежат линейному классу\footnote{В литературе используются также термины
 "аффинные гнезда циклов" \ и "алгоритмы с аффинными зависимостями".}.
 Это означает:

 %--  в программе используется любое количество
 % простых переменных и переменных с индексами;

 -- исполняемым оператором может быть только оператор
  присваивания, правая часть которого является арифметическим выражением;
  операторы-вызовы функций запрещены;

 -- повторяющиеся операции описываются только с помощью циклов,
   эквивалентных do-циклам языка программирования Fortran;
    %структура вложенности циклов может быть произвольной;
    шаги изменения параметров циклов равны +1;

 -- %допускается использование любого количества условных и безусловных
   операторы перехода передают управление "вниз"\ по тексту
   (но не создают циклических конструкций);

 -- индексные выражения переменных, границы изменения параметров
  циклов и условия передачи управления задаются, в общем случае,
  аффинными функциями от параметров циклов и внешних
  переменных\footnote{Внешние переменные программы --- переменные,
  значение которых не изменяется и не определено до начала
  выполнения программы.},
  т.е. неоднородными формами, линейными по совокупности параметров
  циклов и внешних переменных программы (запрещены фрагменты:
  $i*j$, $N_1*N_2$, ${\rm if}(a(i,j)...)$);

 -- параметры функций и внешние переменные программы
 целочисленные.

 Многие программы принадлежат линейному классу или
 могут быть приведены к линейным с
 помощью различных преобразований. Примеры таких преобразований:
 прямая подстановка переменных при вычислении параметров циклов
 (чтобы все переменные зависели только от параметров циклов,
 а не от других
 переменных: выражения типа $a(b(i,j))$ запрещены),
 замена циклических конструкций типа goto на do-циклы,
 замена произведения внешних переменных новой внешней переменной.

 Для отображения алгоритмов, задаваемых последовательными программами,
 на параллельные компьютеры с распределенной памятью, требуется

 1) распределить операции  алгоритма между процессорами,

 2) распределить данные (элементы массивов) между процессорами,

 3) установить порядок выполнения операций в каждом процессоре,

 4) организовать обмен данными.

 Это задачи общие.
 Далее мы рассмотрим более конкретные задачи.
 %Не все задачи, которые будут рассмотрены, требуется решать,
 %если алгоритм хорошо понятен.
 %Если же детали алгоритма не очень понятны,
 %то требуется знание формализованных методов
 %статического распараллеливания, а также средств автоматизации распараллеливания.
  Основное внимание следует уделять распараллеливанию гнезд
  циклов, так как именно циклами часто
 описывается большая часть вычислений,
 и основной ресурс параллелизма относится к циклам.


 \bigskip
%\newpage


\centerline{\bf 1. Поиск информационных зависимостей, }
\centerline{\bf получение информационной структуры алгоритма}

\medskip

Любые процедуры распараллеливания
 должны опираться на точное или избыточное описание
 зависимых операций алгоритма. Если для распараллеливания
 использовать неполное описание зависимостей, то
 необходима проверка корректности полученного параллельного алгоритма.



 Знание одних только зависимостей позволяет
 определять параллельные циклы,
 во многих случаях организовывать параллельные процессы вычислений,
 выявлять избыточные вычисления,
 восстанавливать из программы математические соотношения.


  \setlength{\unitlength}{0.9 mm}
 \begin{picture}(70,75)
{
%\small

%
% EDG for prim2 (mv)
%
\put(4,2){\begin{picture}(70,70) {
%
% vertices
%
  \multiput(27.5,12.5)(15,0){3}{\circle{5}}
  \multiput(27.5,12.5)(15,0){3}{\makebox(0,0){$$}}
    \multiput(27.5,27.5)(15,0){3}{\circle{5}}
    \multiput(27.5,27.5)(15,0){3}{\makebox(0,0){$$}}
  \multiput(27.5,42.5)(15,0){3}{\circle{5}}
  \multiput(27.5,42.5)(15,0){3}{\makebox(0,0){$$}}
    \multiput(27.5,57.5)(15,0){3}{\circle{5}}
    \multiput(27.5,57.5)(15,0){3}{\makebox(0,0){$$}}
%
%  vectors
%
  \multiput(27.5,15.0)(15,0){3}{\vector(0,1){9.6}}
  \multiput(27.5,30.0)(15,0){3}{\vector(0,1){9.6}}
  \multiput(27.5,45.0)(15,0){3}{\vector(0,1){9.6}}

% osi
  \put(0,8.5){\vector(1,0){9}}
  \put(0,8.5){\vector(0,1){9}}
  \put(3.4,15.5){\makebox(0,0){$j$}}
  \put(7.9,5.0){\makebox(0,0){$i$}}

}
\end{picture}}
%
}
\end{picture}
%\smallskip
\setlength{\unitlength}{0.4mm}
 \begin{picture}(150,145)
{

%
% EDG для решения СЛАУ методом обратной подстановки
%
\put(40,15){\begin{picture}(140,145) {
%
%
% vertices (j=0)
   \put(10,10){\circle{11}}
   \put(40,10){\circle{11}}
   \put(70,10){\circle{11}}
   \put(100,10){\circle{11}}
   \put(130,10){\circle{11}}

% vertices (j=1)
   \put(40,40){\circle{11}}
   \put(70,40){\circle{11}}
   \put(100,40){\circle{11}}
   \put(130,40){\circle{11}}

% vertices (j=2)
   \put(70,70){\circle{11}}
   \put(100,70){\circle{11}}
   \put(130,70){\circle{11}}

%
% vertices (j=3)
   \put(100,100){\circle{11}}
   \put(130,100){\circle{11}}

%
% vertices (j=4)
   \put(130,130){\circle{11}}

%  vectors (j=0)
  \put(14.2,14.2){\vector(1,1){21.5}}
    \put(15.2,13.0){\vector(2,1){49.0}}
      \put(15.4,12.0){\vector(3,1){78.5}}
        \put(15.5,11.0){\vector(4,1){108.5}}

  \put(40.0,16.0){\vector(0,1){18.2}}
  \put(70.0,16.0){\vector(0,1){18.2}}
  \put(100.0,16.0){\vector(0,1){18.2}}
  \put(130.0,16.0){\vector(0,1){18.2}}

%  vectors (j=1)
  \put(44.2,44.2){\vector(1,1){21.5}}
    \put(45.2,43.0){\vector(2,1){49.0}}
      \put(45.4,42.0){\vector(3,1){78.5}}

  \put(70.0,46.0){\vector(0,1){18.2}}
  \put(100.0,46.0){\vector(0,1){18.2}}
  \put(130.0,46.0){\vector(0,1){18.2}}

%  vectors (j=2)
  \put(74.2,74.2){\vector(1,1){21.5}}
    \put(75.2,73.0){\vector(2,1){49.0}}

  \put(100.0,76.0){\vector(0,1){18.2}}
  \put(130.0,76.0){\vector(0,1){18.2}}

%  vectors (j=3)
  \put(104.2,104.2){\vector(1,1){21.5}}

  \put(130.0,106.0){\vector(0,1){18.2}}

}
\end{picture}}

}
\end{picture}

 Пусть в первом из алгоритмов, представленных изображенными графами, внешним
 циклом является цикл по $i.$ Анализ зависимостей позволяет
 сделать вывод, что нет зависимостей между операциями,
 приписанными точкам с различным значением  $i.$
 Следовательно, внешний цикл является параллельным.

 Пусть во втором алгоритме внешним
 циклом является цикл по $j.$ При фиксированном $j$
 зависимости между операциями отсутствуют.
 Следовательно, внутренний цикл является параллельным.

\medskip

 Во многих случаях получение информационной структуры алгоритма является
 трудной задачей и требует применения специальных методов.
 %Отметим системы поиска
 %точного описания зависимостей (поиска тонкой информационной
 %структуры алгоритма): V-Ray (Москва, Воеводин Вл.В.),
 %ОРС (Ростов, Штейнберг Б.Я.), LooPo (университет Passau).


\bigskip

%\newpage

\centerline{\bf 2. Обнаружение потенциального параллелизма }

\medskip

 Согласно третьему закону Амдала ускорение
 вычислительной системы не может превзойти обратной величины доли
 последовательных вычислений.
 Например, если доля последовательных вычислений
 составляет всего  1\%, то ни при каком числе процессоров
 нельзя добиться ускорения более чем в 100 раз.

 Таким образом, прежде чем параллелизм использовать, его нужно выявить,
 желательно как можно больше, чтобы знать возможности
 выполнения операций алгоритма одновременно.

 Мы уже видели, что параллельные циклы можно обнаруживать
 посредством анализа зависимостей.

 Более общий математический аппарат для
 распараллеливания дает таймирование (scheduling).
  Методы таймирования позволяют
  с помощью так называемых таймирующих функций получать
 параллельные множества операций,
 организовывать  параллельные вычислительные процессы,
 строить параллельные формы алгоритма.
 Здесь мы будем использовать равносильное
 таймирующей функции понятие --- развертка графа алгоритма.

 Рассмотрим вещественный функционал, определенный на
 вершинах графа алгоритма. Функционал называется разверткой графа,
 если он не убывает вдоль дуг графа.
  Развертка называется строгой, если функционал вдоль дуг графа возрастает.
 Развертка называется расщепляющей, если ее значения равны на любых двух
 вершинах, соединенных дугой.

 Строгие развертки задают параллельные формы алгоритма.
 К одному ярусу параллельной формы относятся
 поверхности уровня развертки.
 Расщепляющие развертки задают параллельные множества.
 Знание хотя бы двух независимых разверток
 позволяет задать параллельные последовательности
 вычислений, конвейерный параллелизм.
 Сказанное иллюстрируется с помощью рисунков.

\setlength{\unitlength}{1.0mm}
 \begin{picture}(160,60)
%
% 1
%
\put(-15,7){\begin{picture}(60,50)

   {\footnotesize \multiput(8.0,10.0)(15,0){1}{\makebox(0,0){$(1,1)$}}}
\multiput(12.5,12.5)(10,0){4}{\circle*{2}}
  \multiput(14,12.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,14)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,22.5)(10,0){4}{\circle*{2}}
  \multiput(14,22.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,24)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,32.5)(10,0){4}{\circle*{2}}
  \multiput(14,32.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,34)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,42.5)(10,0){4}{\circle*{2}}
  \multiput(14,42.5)(10,0){3}{\vector(1,0){7}}
%
 \multiput(7.5,17.5)(30,30){2}{\line(1,-1){10}}
   \put(18.5,6){1}
   \put(48.5,36){7}
 \multiput(7.5,27.5)(20,20){2}{\line(1,-1){20}}
   \put(28.5,6){2}
   \put(48.5,26){6}
 \multiput(7.5,37.5)(10,10){2}{\line(1,-1){30}}
   \put(38.5,6){3}
   \put(48.5,16){5}
 \multiput(7.5,47.5)(30,30){1}{\line(1,-1){40}}
   \put(48.5,6){4}

 %{
 %\large
 % \put(12,0){\makebox(0,0){($a$)}}
 %}
\end{picture}}

%
% 2
%

\put(48,7){\begin{picture}(50,40)

%
   {\footnotesize \multiput(8.0,10.0)(15,0){1}{\makebox(0,0){$(1,1)$}}}
\multiput(12.5,12.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,14)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,22.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,24)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,32.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,34)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,42.5)(10,0){4}{\circle*{2}}

  \multiput(17.5,3.5)(0,4){11}{\line(0,1){2.5}}
  \multiput(27.5,3.5)(0,4){11}{\line(0,1){2.5}}
  \multiput(37.5,3.5)(0,4){11}{\line(0,1){2.5}}

   \put(12.0,5){1}
   \put(22.0,5){2}
   \put(32.0,5){3}
   \put(42.0,5){4}

\end{picture}}

%
% 3
%

\put(100,7){\begin{picture}(50,40)

%
   {\footnotesize \multiput(8.0,10.0)(15,0){1}{\makebox(0,0){$(1,1)$}}}
\multiput(12.5,12.5)(10,0){4}{\circle*{2}}
  \multiput(14,12.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,14)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,22.5)(10,0){4}{\circle*{2}}
  \multiput(14,22.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,24)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,32.5)(10,0){4}{\circle*{2}}
  \multiput(14,32.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,34)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,42.5)(10,0){4}{\circle*{2}}
  \multiput(14,42.5)(10,0){3}{\vector(1,0){7}}

  \multiput(17.5,3.5)(0,4){11}{\line(0,1){2.5}}
  \multiput(27.5,3.5)(0,4){11}{\line(0,1){2.5}}
  \multiput(37.5,3.5)(0,4){11}{\line(0,1){2.5}}
   \put(12.0,5){1}
   \put(22.0,5){2}
   \put(32.0,5){3}
   \put(42.0,5){4}

  \multiput(51.1,17.5)(-4,0){11}{\line(-1,0){2.5}}
  \multiput(51.1,27.5)(-4,0){11}{\line(-1,0){2.5}}
  \multiput(51.1,37.5)(-4,0){11}{\line(-1,0){2.5}}
   \put(47.0,11){1}
   \put(47.0,21){2}
   \put(47.0,31){3}
   \put(47.0,41){4}

\end{picture}}


\end{picture}


 На первом рисунке
 ярусы параллельной формы  алгоритма задаются строгой разверткой
 $t(i,j)=i+j-1.$
 На втором рисунке параллельные множества задаются
 расщепляющей разверткой $t(i,j)=i.$
 Третий рисунок поясняет задание конвейерного параллелизма
 с помощью двух независимых разверток
  $t(i,j)=i$ и $t(i,j)=j.$
 Одна из разверток задает номер процессора,
 другая --- порядок выполнения процессором операций.

 \bigskip
 %\newpage

\centerline{\bf 3. Выявление независимых частей программы}

\medskip

 Выявление независимых частей программы, то есть
  параллельных множеств, ---
   случай обнаружения параллелизма, особенно важного
   для компьютеров с распределенной памятью.

 В ряде случаев каждое параллельное множество может быть представлено
 гиперплоскостью пространства итераций; в этом случае число
 независимых частей пропорционально размеру задачи.
 Способы получения такого параллелизма называются методами гиперплоскостей
 (Lamport).
 В других случаях, независимо от размера задачи, параллельных множеств
 два или несколько. Методы, позволяющие выявлять такие разбиения алгоритма
 на независимые части называются методами параллелепипедов.
 Такое название обусловлено тем, что получаемые в результате области
 независимых итераций можно представить в виде параллелепипедов
 или в виде вырожденных параллелепипедов.

\setlength{\unitlength}{1.0mm}
 \begin{picture}(160,50)

\put(-15,-3){\begin{picture}(50,50)
%
\multiput(12.5,12.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,14)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,22.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,24)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,32.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,34)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,42.5)(10,0){4}{\circle*{2}}

\end{picture}}

\put(45,-3){\begin{picture}(50,50)
%
\multiput(12.5,12.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,14)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,22.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,24)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,32.5)(10,0){4}{\circle*{2}}
    \multiput(12.5,34)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,42.5)(10,0){4}{\circle*{2}}

  \multiput(13.8,12)(10,0){2}{\line(2,-1){8.8}}
     \multiput(22.7,7.7)(10,0){2}{\vector(2,1){8.6}}
  \multiput(13.8,22)(10,0){2}{\line(2,-1){8.8}}
     \multiput(22.7,17.7)(10,0){2}{\vector(2,1){8.6}}
  \multiput(13.8,32)(10,0){2}{\line(2,-1){8.8}}
     \multiput(22.7,27.7)(10,0){2}{\vector(2,1){8.6}}
  \multiput(13.8,42)(10,0){2}{\line(2,-1){8.8}}
     \multiput(22.7,37.7)(10,0){2}{\vector(2,1){8.6}}

\end{picture}}

\put(105,-3){\begin{picture}(50,50)
%
 \multiput(12.5,12.5)(10,0){4}{\circle*{2}}
 \multiput(12.5,22.5)(10,0){4}{\circle*{2}}
 \multiput(12.5,32.5)(10,0){4}{\circle*{2}}
 \multiput(12.5,42.5)(10,0){4}{\circle*{2}}

   \multiput(13.5,13.5)(10,0){3}{\vector(1,1){8.1}}
      \multiput(21.5,13.5)(10,0){3}{\vector(-1,1){8.1}}
   \multiput(13.5,23.5)(10,0){3}{\vector(1,1){8.1}}
      \multiput(21.5,23.5)(10,0){3}{\vector(-1,1){8.1}}
   \multiput(13.5,33.5)(10,0){3}{\vector(1,1){8.1}}
      \multiput(21.5,33.5)(10,0){3}{\vector(-1,1){8.1}}


\end{picture}}


\end{picture}

 Параллельные множества в методах гиперплоскостей задаются
 аффинными таймирующими функциями, а в методах параллелепипедов ---
 модульными аффинными таймирующими функциями.

 В реальных алгоритмах, представленных программной единицей,
  декомпозиция  на независимые части возможна не часто.
   Примерами могут быть алгоритмы
  умножение матрицы на вектор (см. первый рисунок) и  матрицы на матрицу,
  а также алгоритм Якоби
  решения задачи Дирихле для уравнения Пуассона
  (разбивается на два блока независимых вычислений, см. третий рисунок).


\bigskip

%\newpage

% \centerline{\bf 4. Пространственно-временное отображение }
% \centerline{\bf  на виртуальные процессоры}

%\medskip

% Пространственно-временное отображение (space-time mapping)
% ---  распределение
% операций между виртуальными процессорами и задание
% порядка выполнения операций.

 %Пусть имеется набор независимых разверток (многомерное таймирование).
 %Будем считать, что $r$  разверток
 % задают пространственное отображение операций
 %алгоритма в $r$-мерное пространство виртуальных процессоров,
 %а оставшиеся развертки --- упорядочение
 %(выполнение в лексикографическом порядке)
 %вычислений, выполняемых процессорами.
 %Таким образом, значения параметров $r$ циклов
 %преобразованного с помощью набора разверток
 %(в другой терминологии  ---
 %с помощью многомерного таймирования гнезда циклов)
 %определяют координаты процессора,
 %а значения параметров оставшихся циклов --- итерации,
 %которые этим процессором должны выполняться.



%  Можно
    %, как это делалось в диссертации Бахановича,
%  пространственно-временное отображение
%  задавать пространственным отображением операций и
%  согласованным с этим отображением одномерным (скалярным) таймированием.
%  Такие методы распараллеливания требуют больше усилий
% (по сравнению с использованием векторного таймирования для
% упорядочения вычислений) для получения SPMD кода.




 \centerline{{\bf 4. Предварительное преобразование
 алгоритма}\footnote{Этот этап получения параллельных алгоритмов может отсутствовать.}}

\medskip

   Предварительное преобразование может применяться для улучшения параллельных
 свойств алгоритма.

 Приведем пример.
  Рассмотрим один из алгоритмов умножения матрицы порядка $N$ на вектор
  и несколько упрощенный соответствующий граф зависимостей ($N=3$) :

$
%\begin{equation*}
\begin{array}{l}
 \hspace{0mm} \mbox{do} \ \ i=1,N\\
 \hspace{6mm}   r=0\\
 \hspace{6mm} \mbox{do} \ \ j=1,N\\
 \hspace{12mm}  r=r+a(i,j)b(j)\\
 \hspace{6mm} \mbox{enddo}\\
 \hspace{6mm}   c(i)=r\\
 \hspace{0mm} \mbox{enddo}
 \end{array}
% \label{mv}
% \end{equation*}
$
\setlength{\unitlength}{0.9mm}
 \begin{picture}(60,20)

\put(15,-30){\begin{picture}(50,20)
%
 \multiput(12.5,12.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,14)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,22.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,24)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,32.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,34)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,42.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,44)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,52.5)(10,0){3}{\circle*{2}}
         \multiput(12.5,51.5)(10,0){2}{\vector(1,-4){9.5}}

\end{picture}}

\end{picture}

\noindent
 Алгоритм является последовательным:
 переменная $r$ порождает зависимости
 (в том числе и так называемые ложные зависимости),
 связывающие последовательно все итерации гнезда циклов.
 Поэтому нельзя организовать параллельные вычисления,
 использующие общую память (нельзя, например, запустить
 несколько потоков на многоядерном процессоре).
 После применения стандартного приема увеличения
 размерности массива
 %(в данном случае --- переменной $r$)
 получаем хорошо распараллеливаемый алгоритм:
%\begin{equation*}

$
\begin{array}{l}
 \hspace{0mm} \mbox{do} \ \ i=1,N\\
 \hspace{6mm}  r(i)=0\\
 \hspace{6mm} \mbox{do} \ \ j=1,N\\
 \hspace{12mm} r(i)=r(i)+a(i,j)b(j)\\
 \hspace{6mm} \mbox{enddo}\\
 \hspace{6mm}  c(i)=r(i)\\
 \hspace{0mm} \mbox{enddo}
 \end{array}
$
% \label{mvri}
% \end{equation*}
\setlength{\unitlength}{0.9mm}
 \begin{picture}(60,20)

\put(15,-30){\begin{picture}(50,20)
%
 \multiput(12.5,12.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,14)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,22.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,24)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,32.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,34)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,42.5)(10,0){3}{\circle*{2}}
    \multiput(12.5,44)(10,0){3}{\vector(0,1){7}}
 \multiput(12.5,52.5)(10,0){3}{\circle*{2}}

\end{picture}}

\end{picture}

 Предварительное преобразование применяется также для улучшения коммуникационной структуры
 синтезируемого параллельного алгоритма и (или) для возможности получения
 координатных информационных разрезов
 алгоритма.

\setlength{\unitlength}{0.8mm}
 \begin{picture}(160,55)


\put(-10,-7){\begin{picture}(50,40)

%
  \multiput(10,10)(0,30){2}{\line(1,0){60}}
   \multiput(10,10)(20,0){4}{\line(0,1){30}}
    \multiput(10,10)(20,0){4}{\line(1,1){15}}
       \multiput(25,25)(0,30){2}{\line(1,0){60}}
        \multiput(25,25)(20,0){4}{\line(0,1){30}}
         \multiput(10,40)(20,0){4}{\line(1,1){15}}

  \multiput(10,10)(0,0){1}{\vector(1,0){10}}
  \multiput(10,10)(0,0){1}{\vector(1,1){7}}
%  \multiput(10,10)(0,0){1}{\vector(0,1){10}}
       \multiput(30,10)(0,0){1}{\vector(-1,3){3.5}}
       \multiput(26.5,10.2)(0,2.5){4}{\line(0,1){1.50}}

 {\small
   \put(15.0,4){$Pr_1$}
   \put(35.0,4){$Pr_2$}
   \put(55.0,4){$Pr_3$}
 }

\end{picture}}



\put(90,-7){\begin{picture}(50,40)

%
  \multiput(10,10)(10,30){2}{\line(1,0){60}}
   \multiput(30,10)(20,0){3}{\line(0,1){30}}
    \multiput(10,10)(20,0){4}{\line(1,1){15}}
       \multiput(25,25)(10,30){2}{\line(1,0){60}}
        \multiput(45,25)(20,0){3}{\line(0,1){30}}
         \multiput(30,40)(20,0){3}{\line(1,1){15}}
  \multiput(10,10)(60,0){2}{\line(1,3){10}}
  \multiput(25,25)(60,0){2}{\line(1,3){10}}
  \multiput(20,40)(60,0){2}{\line(1,1){15}}

  \multiput(10,10)(0,0){1}{\vector(1,0){10}}
  \multiput(10,10)(0,0){1}{\vector(1,1){7}}
 % \multiput(10,10)(0,0){1}{\vector(1,3){3.5}}
  \multiput(30,10)(0,0){1}{\vector(0,1){10.0}}

 {\small
   \put(15.0,4){$Pr_1$}
   \put(35.0,4){$Pr_2$}
   \put(55.0,4){$Pr_3$}
   \put(72.0,4){$Pr_4$}
 }

\end{picture}}

\end{picture}

\bigskip

 На рисунках схематично представлены
 множества операций, выполняемых на одном
 процессоре, некоторого исходного и преобразованного
 алгоритмов; векторы символизируют дуги в графе алгоритма.
 Для реализации преобразованного алгоритма требуется меньше
 коммуникаций.
 Кроме того, преобразованный алгоритм допускает
 информационные разрезы по всем координатам итерационного
 пространства, что важно для получения зернистых алгоритмов
 (т.е. алгоритмов, операции которых объединенными в макрооперации).

\bigskip



\centerline{\bf 5. Тайлинг}

\medskip

 Тайлинг (tiling) --- получение макроопераций (получение зерна вычислений,
 тайлов).
 Под зерном вычислений (или тайлом) понимается множество операций алгоритма,
 выполняемых атомарно: вычисления, принадлежащие одному зерну,
 не могут прерываться синхронизацией или обменом данными,
 требуемыми для выполнения этих операций.
 Обычно результаты вычислений одного тайла формируют пакет
 данных для пересылки другому процессору.
  Тайлинг очень часто применяется как при использовании
  компьютеров
 с распределенной памятью, так и при использовании многоядерных
 персональные компьютеры и графических процессоров.

При тайлинге каждый цикл разбивается на два цикла: глобальный,
параметр которого определяет на данном уровне вложенности порядок
вычисления тайлов, и локальный, в котором параметр исходного цикла
изменяется в границах одного тайла. Допускается вырожденное
разбиение цикла, при котором все итерации относятся к глобальному
циклу или все итерации относятся к локальному циклу. Локальные
циклы переставляются с глобальными и становятся самыми
внутренними.

\setlength{\unitlength}{0.9mm}
 \begin{picture}(160,52)

\put(25,-7){\begin{picture}(50,40)

%
  \multiput(10,10)(0,30){2}{\line(1,0){60}}
   \multiput(10,10)(20,0){4}{\line(0,1){30}}
    \multiput(10,10)(20,0){4}{\line(1,1){15}}
       \multiput(25,25)(0,30){2}{\line(1,0){60}}
        \multiput(25,25)(20,0){4}{\line(0,1){30}}
         \multiput(10,40)(20,0){4}{\line(1,1){15}}

% тайлы
%
 {
 \thicklines
  \multiput(10,10)(0,5){2}{\line(1,0){20}}
   \multiput(10,10)(20,0){2}{\line(0,1){5}}
       \multiput(10,10)(20,0){2}{\line(1,1){4}}
       \multiput(14,14)(0,5){2}{\line(1,0){20}}
        \multiput(14,14)(20,0){2}{\line(0,1){5}}
         \multiput(10,15)(20,0){2}{\line(1,1){4}}
  \multiput(30,10)(7,7){2}{\line(1,0){20}}
       \multiput(30,10)(20,0){2}{\line(1,1){7}}
 }
        \multiput(30,10)(1,0){20}{\line(1,1){7}}

 {\small
   \put(15.0,4){$Pr_1$}
   \put(35.0,4){$Pr_2$}
   \put(55.0,4){$Pr_3$}
 }

\end{picture}}

\end{picture}

\bigskip

 На рисунке приведены примеры трехмерного и двумерного тайлов.


 \bigskip

 \centerline{\bf 6. Организация параллельных вычислительных процессов}

\medskip

   Пусть алгоритм, заданный гнездом циклов, имеет
 один или несколько параллельных самых внешних циклов.
 В этом случае в явном виде заданы параллельные
 множества операций, и алгоритм разбивается на независимые части.
 Если параллельными являются один или несколько самых внутренних
 циклов, то в явном виде задана параллельная форма алгоритма.
 В обоих случаях параллельные вычислительные процессы или параллельные
 потоки (нити) можно организовать, выполняя независимо операции
 параллельных циклов.

 Если алгоритм не имеет параллельных циклов, но обладает внутренним
 параллелизмом (достаточным условием для этого является существование
 двух независимых разверток графа алгоритма), то можно выделить
 параллельные последовательности вычислений, т.е. можно указать
 упорядоченные множества операций алгоритма,
 которые могут выполняться одновременно.
 В этом случае явного указания операций, выполняемых одновременно, не требуется.

 \setlength{\unitlength}{1.0mm}
 \begin{picture}(160,50)

\put(0,-7){\begin{picture}(50,40)

%
\multiput(12.5,12.5)(10,0){4}{\circle*{2}}
  \multiput(14,12.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,14)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,22.5)(10,0){4}{\circle*{2}}
  \multiput(14,22.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,24)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,32.5)(10,0){4}{\circle*{2}}
  \multiput(14,32.5)(10,0){3}{\vector(1,0){7}}
    \multiput(12.5,34)(10,0){4}{\vector(0,1){7}}
\multiput(12.5,42.5)(10,0){4}{\circle*{2}}
  \multiput(14,42.5)(10,0){3}{\vector(1,0){7}}

  \multiput(17.5,3.5)(0,4){11}{\line(0,1){2.5}}
  \multiput(27.5,3.5)(0,4){11}{\line(0,1){2.5}}
  \multiput(37.5,3.5)(0,4){11}{\line(0,1){2.5}}
 {\small
   \put(9.5,6){$Pr_1$}
   \put(19.5,6){$Pr_2$}
   \put(29.5,6){$Pr_3$}
   \put(39.5,6){$Pr_4$}
 }

\end{picture}}

\setlength{\unitlength}{0.9mm}

\put(70,-7){\begin{picture}(50,40)

%
  \multiput(10,10)(0,30){2}{\line(1,0){60}}
   \multiput(10,10)(10,0){7}{\line(0,1){30}}
    \multiput(10,10)(10,0){7}{\line(1,1){15}}
       \multiput(25,25)(0,30){2}{\line(1,0){60}}
        \multiput(25,25)(10,0){7}{\line(0,1){30}}
         \multiput(10,40)(10,0){7}{\line(1,1){15}}

 {\small
   \put(5.0,5){$Pr_1$}
   \put(15.0,5){$Pr_2$}
   \put(25.0,5){$Pr_3$}
   \put(35.0,5){$Pr_4$}
   \put(45.0,5){$Pr_5$}
   \put(55.0,5){$Pr_6$}
   \put(65.0,5){$Pr_7$}
 }

\end{picture}}


\end{picture}

\bigskip

  Пример --- рассмотренное ранее для двумерного алгоритма
   получение конвейерного
   параллелизма с помощью двух независимых разверток.
   Операции, приписанные точкам на рисунке, можно выполнять  параллельно,
 если одна координата точек задает номер процесса,
 другая --- порядок выполнения операций. После выполнения операции
 данные передаются процессу с большим номером.
 Аналогично осуществляется организация параллельных вычислительных процессов
 и для алгоритмов большей размерности.

 Как правило, для эффективной реализации алгоритма на параллельном
 компьютере следует сначала осуществить тайлинг,
 получить макрооперации и для распараллеливания
 рассматривать только глобальные циклы.


\bigskip

\centerline{\bf 7. Согласование распределения операций и данных}
\centerline{\bf между процессорами. Приватизация массивов}

\medskip

 Согласование распределения операций и данных по
 процессорам (alignment) необходимо для
 минимизации числа и объема обменов данными.
 Требуется распределить операции и массивы данных
 так, чтобы коммуникаций было как можно меньше.

 Операции обмена данными выполняются гораздо дольше
 вычислительных операций, поэтому производительность
 многопроцессорной вычислительной системы
 с распределенной памятью в значительной
 степени зависит от оптимальности решения задачи распределения
 данных.

 Наиболее благоприятным результатом
 согласования распределения операций и данных
 является приватизации данных, т.е. выделение
 массивов или частей массивов, локализованных в процессорах.
 Элементы приватизированного массива требуются
 для вычислений только в одном процессоре и поэтому не участвуют
 в операциях обмена данными.

 Приведем пример приватизации данных.
 Рассмотрим алгоритм перемножения матрицы
 $A$ и вектора $b$ порядка $N;$
 выходными данными алгоритма являются
 координаты  вектора $c:$ %\linebreak
 $c_i=\msum^N_{j=1} a_{ij}b_j,$
 $1\leqslant i\leqslant N.$
\begin{equation*}
\begin{array}{l}
\hspace{0mm} \mbox{do} \ \ i=1,N\\
 \hspace{6mm} S_1: \ c(i)=0\\
\hspace{6mm} \mbox{do} \ \ j=1,N\\ \hspace{12mm} S_2: \
c(i)=c(i)+a(i,j)b(j)\\ \hspace{6mm} \mbox{enddo}\\ \hspace{0mm}
\mbox{enddo}
\end{array}
%\label{mv}
\end{equation*}

 Изобразим  граф алгоритма ($N=3$),
 вершины помечены
 необходимыми для выполнения операций элементами массивов.

\setlength{\unitlength}{1.00mm}
 \begin{picture}(70,85)
{
%
% EDG для умножения матрицы вектор
%
\put(30,6){\begin{picture}(70,80) {
%
% vertices
%
 \multiput(10,10)(0,20){4}{\circle{11}}
 \multiput(30,10)(0,20){4}{\circle{11}}
 \multiput(50,10)(0,20){4}{\circle{11}}
%
%data
%
 {\scriptsize
   \put(10,10){\makebox(0,0){$c(1)$}}
   \put(30,10){\makebox(0,0){$c(2)$}}
   \put(50,10){\makebox(0,0){$c(3)$}}

     \multiput(10,33)(0,20){3}{\makebox(0,0){$c(1)$}}
     \multiput(30,33)(0,20){3}{\makebox(0,0){$c(2)$}}
     \multiput(50,33)(0,20){3}{\makebox(0,0){$c(3)$}}

   \put(10,30.0){\makebox(0,0){$a(1,1)$}}
   \put(30,30.0){\makebox(0,0){$a(2,1)$}}
   \put(50,30.0){\makebox(0,0){$a(3,1)$}}
     \put(10,50.0){\makebox(0,0){$a(1,2)$}}
     \put(30,50.0){\makebox(0,0){$a(2,2)$}}
     \put(50,50.0){\makebox(0,0){$a(3,2)$}}
   \put(10,70.0){\makebox(0,0){$a(1,3)$}}
   \put(30,70.0){\makebox(0,0){$a(2,3)$}}
   \put(50,70.0){\makebox(0,0){$a(3,3)$}}

     \multiput(10,27)(20,0){3}{\makebox(0,0){$b(1)$}}
     \multiput(10,47)(20,0){3}{\makebox(0,0){$b(2)$}}
     \multiput(10,67)(20,0){3}{\makebox(0,0){$b(3)$}}
 }
%
%  vectors
%
 \multiput(10.0,16.0)(0,20){3}{\vector(0,1){8.2}}
 \multiput(30.0,16.0)(0,20){3}{\vector(0,1){8.2}}
 \multiput(50.0,16.0)(0,20){3}{\vector(0,1){8.2}}
%
%  Pr
%
   \put(10,-1.0){\makebox(0,0){$Pr_1$}}
   \put(30,-1.0){\makebox(0,0){$Pr_2$}}
   \put(50,-1.0){\makebox(0,0){$Pr_3$}}
}
\end{picture}}

}
\end{picture}

 \noindent
 Пусть элементы $c_i$ массива $c$ вычисляются в процессоре $Pr_i.$
 Тогда процессор $Pr_i$ приватизирует элемент $c_i$
  и $i$-ю строку массива $a.$
 В каждом процессоре используется весь массив $b.$

\medskip

 %Распределение элементов массивов данных можно осуществлять
 % с помощью специальных функций.

 %Можно еще на стадии получения пространственно-временного отображения
 %учитывать условия (условия локализации данных), позволяющие лучше
 %согласовать распределения операций и данных по процессорам.

 %Основные исследования по согласованию распределения операций и данных
 %относятся к статическому распределению.
 %Для вычислительных алгоритмов больше подходит динамическое
 %распределение данных.


\bigskip

%\newpage

\centerline{\bf 8. Выделение используемых процессорами массивов}

\medskip

 Для каждого процессора необходимо определить массивы или части
  массивов, используемые процессором в вычислениях.
  Соответственно изменяются размеры массивов и текст программы.
  В примере из прошлого пункта
   в каждом процессоре вместо двумерного массива $a$
  будет использоваться одномерный массив.



\bigskip


%\centerline{\bf . Блокинг}

%\medskip

%Блокинг (blocking\footnote{В литературе этот термин выходит из
%употребления.})

%\bigskip


\centerline{\bf 9. Оптимизация числа и объема временных массивов}

\medskip


 Объем массивов данных существенно влияет на скорость работы с памятью.
 С другой стороны, уменьшение объема массивов может ухудшить
 параллельные свойства алгоритма.
 Например, в рассмотренном выше примере умножения матрицы на вектор
 использование массива $r$ меньшего объема уменьшает ресурс параллелизма.
 Поэтому при извлечении параллелизма важно уметь оптимизировать размеры массивов
 за счет расширения или сжатия массив.
 Под сжатием массива понимается аннулирование какой-либо
 размерности массива и замена его в коде программы новым массивом
 меньшей размерности. Подразумевается, что такая замена допустима
 и результаты вычислений не изменятся.
 Отметим, что задача выявления массивов, для которых возможно сжатие,
 является NP-полной.

\bigskip

\bigskip

\bigskip

\bigskip

\bigskip

\bigskip

\bigskip

\bigskip

\centerline{\bf 10.  Получение коммуникационных операций.}
\centerline{\bf Структурирование коммуникаций}

\medskip

 На практике даже оптимальное согласование распределения операций и данных
  между процессорами не исключает необходимости вводить
  коммуникации.
 Возникает задача генерации (включения) коммуникационных операций в параллельный  алгоритм.
  Теория включения в код коммуникационных операций разработана недостаточно,
  поэтому для организации обмена данными требуется хорошее
  понимание реализуемого алгоритма.

 На параллельных компьютерах с распределенной памятью
 структурированные коммуникации, например бродкаст (broadcast),
 а также трансляция (translation) данных выполняются быстрее,
 чем большое количество коммуникаций точка-точка (point-to-point)
 между процессором, в локальной памяти которого хранится данное, и
 каждым процессором, который использует или вычисляет это данное.
 Поэтому желательно выявлять возможность организации таких
 коммуникаций, и только в случаях, когда не удается
 структурировать, использовать коммуникации точка-точка.
 В примере перемножения матрицы и вектора (пункт 7)
 массив $b$ можно не хранить в локальной памяти процессоров, а
   осуществить бродкаст каждого данного $b_1,$
  $b_2,$ $b_3$ ко всем процессорам:

\setlength{\unitlength}{1.00mm}
 \begin{picture}(70,85)
{
%
% EDG для умножения матрицы вектор
%
\put(40,6){\begin{picture}(70,80) {
%
% vertices
%
 \multiput(10,10)(0,20){4}{\circle{11}}
 \multiput(30,10)(0,20){4}{\circle{11}}
 \multiput(50,10)(0,20){4}{\circle{11}}
%
%data
%
 {\scriptsize
   \put(10,10){\makebox(0,0){$c(1)$}}
   \put(30,10){\makebox(0,0){$c(2)$}}
   \put(50,10){\makebox(0,0){$c(3)$}}

     \multiput(10,33)(0,20){3}{\makebox(0,0){$c(1)$}}
     \multiput(30,33)(0,20){3}{\makebox(0,0){$c(2)$}}
     \multiput(50,33)(0,20){3}{\makebox(0,0){$c(3)$}}

   \put(10,30.0){\makebox(0,0){$a(1,1)$}}
   \put(30,30.0){\makebox(0,0){$a(2,1)$}}
   \put(50,30.0){\makebox(0,0){$a(3,1)$}}
     \put(10,50.0){\makebox(0,0){$a(1,2)$}}
     \put(30,50.0){\makebox(0,0){$a(2,2)$}}
     \put(50,50.0){\makebox(0,0){$a(3,2)$}}
   \put(10,70.0){\makebox(0,0){$a(1,3)$}}
   \put(30,70.0){\makebox(0,0){$a(2,3)$}}
   \put(50,70.0){\makebox(0,0){$a(3,3)$}}
  }
%
%  vectors
%
 \multiput(10.0,16.0)(0,20){3}{\vector(0,1){8.2}}
 \multiput(30.0,16.0)(0,20){3}{\vector(0,1){8.2}}
 \multiput(50.0,16.0)(0,20){3}{\vector(0,1){8.2}}

 \multiput(-10,20.0)(0,20){3}{\line(1,0){50.0}}
   {\small
     \multiput(-6,22.5)(20,0){1}{\makebox(0,0){$b(1)$}}
     \multiput(-6,42.5)(20,0){1}{\makebox(0,0){$b(2)$}}
     \multiput(-6,62.5)(20,0){1}{\makebox(0,0){$b(3)$}}
   }
 \multiput(0,20.0)(0,20){3}{\vector(1,1){5.5}}
 \multiput(20,20.0)(0,20){3}{\vector(1,1){5.5}}
 \multiput(40,20.0)(0,20){3}{\vector(1,1){5.5}}


%
%  Pr
%
   \put(10,-1.0){\makebox(0,0){$Pr_1$}}
   \put(30,-1.0){\makebox(0,0){$Pr_2$}}
   \put(50,-1.0){\makebox(0,0){$Pr_3$}}
}
\end{picture}}

}
\end{picture}




\bigskip



\centerline{\bf 11. Улучшение локальности данных}

\medskip

Локальность данного при выполнении какой-либо
 операции означает
 расположение (хранение) его непосредственно перед использованием в памяти
 с быстрым доступом, где оно оказалось вследствие
 участия в более ранней операции. При многопроцессорной обработке памятью с
 быстрым доступом считается локальная память процессора, при
 однопроцессорной --- кэш.
  Локальность алгоритма --- это вычислительное свойство алгоритма,
 отражающее совокупность сведений о локальности его данных.
Улучшить локальность означает реорганизовать вычисления таким
образом, чтобы добиться более частого использования памяти с
быстрым доступом.
 Улучшение локальности данных называют еще локализацией данных.

Локальность параллельного алгоритма,
 предназначенного для реализации на компьютерах с распределенной
 памятью, определяет коммуникационные затраты: чем лучше
 локальность, тем меньше аргументов операций требуется доставлять
 в процессоры.
 %Улучшить локальность фактически означает добиться
 %более согласованного распределения операций и данных между процессорами.


 Для улучшение локальности при
однопроцессорной обработке необходимо, чтобы операции алгоритма,
 которые используют одни и те же или соседние с точки зрения хранения в памяти элементы
 массива данных, выполнялись бы друг за другом.
 Если хранение элементов массива осуществляется по строкам,
 то близко расположенными в памяти
 элементами массива являются элементы, отличающиеся только последней
 координатой.

 Пусть $A$ --- квадратная матрица порядка $N.$ Рассмотрим алгоритм
$LU$ разложения матрицы компактной схемой Гаусса:

$\begin{array}{l} \hspace{0mm}  \mbox{\tt do \it i = 1,N-1}\\
    \hspace{6mm} S_1: \mbox{\it b(i)=1/a(i,i)}\\
    \hspace{6mm} \mbox{\tt do  \it j =i+1,N}\\
        \hspace{12mm} S_2: \mbox{\it a(j,i)=a(j,i)b(i)}\\
        \hspace{12mm} \mbox{\tt do \it k =i+1,N}\\
            \hspace{18mm} S_3: \mbox{\it a(j,k)=a(j,k)-a(j,i)a(i,k)}\\
        \hspace{12mm}  \mbox{\tt enddo}\\
    \hspace{6mm}  \mbox{\tt enddo}\\
\hspace{0mm} \mbox{\tt enddo}\\
\end{array}$

 Основные вычисления определяются оператором $S_3.$
  Если хранение элементов массива осуществляется по строкам,
 то на  всех вхождениях массива $a$ в оператор $S_3$ данные с точки
 зрения локальности данных используются эффективно. Действительно,
 элементы $a(j,k)$ при изменении параметра $k$ самого внутреннего
 цикла являются элементами одной строки массива. То же самое можно
 сказать и относительно элемента $a(i,k),$ а элемент $a(j,i)$
 вообще не изменяется на итерациях $k.$
 Но если переставить местами циклы по $i$ и $j,$
 то получим некоторое улучшение свойства локальности:
 к прежним достоинствам добавится использование элементов одной строки
 $a(j,i)$ при смене параметра внутреннего цикла  по $i.$
 Соответствующее допустимое преобразование задается многомерным
таймированием: $t^{(1)}(i)=(i,i,i),\ t^{(2)}(i,j)=(j,i,i),\
t^{(3)}(i,j,k)=(j,i+1,k),$ и приводит исходный алгоритм к
следующему виду:

 \noindent
 $\begin{array}{l} \hspace{0mm}
  S_1^{\prime}: \mbox{\it b(1)=1/a(1,1)}\\
  \hspace{0mm}  \mbox{\tt do  \it j = 1,N-1}\\
    \hspace{6mm} S_2^{\prime}: \mbox{\it a(j,1)=a(i,1)b(1)}\\
    \hspace{6mm} \mbox{\tt do \it i =2,j-1}\\
        \hspace{12mm} S_2: \mbox{\it a(j,i)=a(j,i)b(i)}\\
        \hspace{12mm} \mbox{\tt do \it k =i,N}\\
            \hspace{18mm} S_3: \mbox{\it a(j,k)=a(j,k)-a(j,i-1)a(i-1,k)}\\
        \hspace{12mm}  \mbox{\tt enddo}\\
    \hspace{6mm}  \mbox{\tt enddo}\\
    \hspace{6mm} S_3^{\prime}: \mbox{\it a(j,j)=a(j,j)-a(j,j-1)a(j-1,j)}\\
    \hspace{6mm} S_1: \mbox{\it b(j)=1/a(j,j)}\\
    \hspace{6mm} \mbox{\tt do \it k =j+1,N}\\
        \hspace{12mm} S_3^{\prime\prime}:
        \mbox{\it a(j,k)=a(j,k)-a(j,j-1)a(j-1,k)}\\
    \hspace{6mm}  \mbox{\tt enddo}\\
\hspace{0mm} \mbox{\tt enddo}
\end{array}$\\
 \noindent $\begin{array}{l} \hspace{0mm}
 S_2^{\prime\prime}: \mbox{\it
 a(N,1)=a(N,1)b(1)}\\
 \hspace{0mm} \mbox{\tt do \it i =2,N-1}\\
    \hspace{6mm} S_2^{\prime\prime\prime}:
    \mbox{\it a(N,i)=a(N,i)b(i)}\\
    \hspace{6mm} \mbox{\tt do \it k =i,N}\\
            \hspace{12mm} S_3^{\prime\prime\prime}:
            \mbox{\it a(N,k)=a(N,k)-a(N,i-1)a(i-1,k)}\\
    \hspace{6mm}  \mbox{\tt enddo}\\
 \hspace{0mm} \mbox{\tt enddo}\\
 \hspace{0mm} S_3^{\prime\prime\prime\prime}:
  \mbox{\it a(N,N)=a(N,N)-a(N,N-1)a(N-1,N)}\\
 \end{array}$\\

 %\smallskip
 \noindent
 С ростом $N$ время вычислений преобразованного и
 непреобразованного алгоритмов
 на однопроцессорном компьютере  может отличаться существенно.


\bigskip

\centerline{\bf 12. Генерация кода}

\medskip

 Генерация кода после распараллеливающих и (или)
 улучшающих структуру программы преобразований
 во многих случаях вызывает затруднение.
 В рассмотренном примере LU-разложения
 код значительно усложнился после сравнительно
 несложного преобразования --- перестановки циклов
 со сдвигом одного из циклов.
  На практике, по-видимому, разумно получать пусть не
 оптимальные, но приемлемые по выбранным критериям
 преобразования циклов, приводящие к
 упрощенной генерации кода.
 Можно воспользоваться средствами
 автоматизации генерации кода [4, 5].


\bigskip

\centerline{\bf 13.  Автоматизация распараллеливания}

\medskip

 Получение и программная реализация параллельных алгоритмов
 задача, как правило, довольно трудоемкая;
 эффективный параллельный алгоритм удается получить не всегда.
 Обращаться к суперкомпьютеру следует тогда, когда
 последовательные реализации алгоритма себя полностью исчерпали.
 В связи с этим особую важность
 и актуальность приобретает разработка методов автоматизированого
 распараллеливания последовательных программ, а также
 создание систем автоматизированного
 распараллеливания, адаптирующих программы к компьютерам с параллельной
 архитектурой.





\bigskip

%\newpage
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%% Литература

{\small

\begin{center}\textbf{Литература}\end{center}

 1.  Воеводин В. В., Воеводин Вл. В. Параллельные вычисления. --
  СПб.: БХВ-Петербург, 2002. -- 600 с.

 2. Воеводин В. В. Вычислительная математика и структура алгоритмов. --
  Москва: Изд-во МГУ, 2006. -- 112 с.\ \
  http://parallel.ru/info/parallel/voevodin/

 3. Антонов А. С., Воеводин Вл. В.
 Эффективная адаптация последовательных программ для современных
 векторно-конвейерных и массивно-парал\-лельных супер-ЭВМ
 // Программирование. 1996. \No~4. С.~37--51.

 4. CLooG: The Chunky Loop Generator. http://www.cloog.org

 5. TLOG: A parameterized tiled loop generator.
   http://www.cs.colostate.edu/ ln/TLOG/

}



\end{document}
