# ЗАДАЧА РАСПОЗНАВАНИЯ С ОБУЧЕНИЕМ


## Шаг 0 (предварительный)
На входе имеем две задачи T₀ и T₁. В каждой из этих задач имеется своя выборка объектов X⁰, разбитая на l классов и соответствующие им информационные вектора. К каждой из этих выборок применяем одинаковую схему решения, описанную ниже.

### Разбиение выборки X⁰ на две части
Шаг может повторяться некоторое число раз. Каждый раз выборка X⁰ разбивается на две части X⁰ₒᵦₓᵧ и X⁰ₖₒₙₜₚ (называются соответственно **обучающей** и **контрольной** выборками). Выборки должны удовлетворять следующим условиям:

X⁰ᵢ₍ₒ₎ ≝ X⁰ₒᵦₓᵧ ∩ X⁰ᵢ ≠ ∅ ∀i ∈ {1, ..., l}, ∪ᵢ₌₁ˡ X⁰ᵢ₍ₒ₎ = X⁰ₒᵦₓᵧ;  
X⁰ᵢ₍ₖ₎ ≝ X⁰ₖₒₙₜₚ ∩ X⁰ᵢ ≠ ∅ ∀i ∈ {1, ..., l}, ∪ᵢ₌₁ˡ X⁰ᵢ₍ₖ₎ = X⁰ₖₒₙₜₚ.

Обозначим: |X⁰ᵢ₍ₒ₎|=mᵢ, |X⁰ᵢ₍ₖ₎| = tᵢ, Σᵢ₌₁ˡ mᵢ = |X⁰ₒᵦₓᵧ| = m, Σᵢ₌₁ˡ tᵢ = |X⁰ₖₒₙₜₚ| = t.

В результате шага 0 может быть получено два разбиения, которые мы обозначим через

{X⁰ₒᵦₓᵧ, X⁰ₖₒₙₜₚ}¹, {X⁰ₒᵦₓᵧ, X⁰ₖₒₙₜₚ}².

При этом первое разбиение сопоставляется задаче T₀, а второе – задаче T₁.

### Ограничение:
Все выборки {X⁰ₒᵦₓᵧ, X⁰ₖₒₙₜₚ}ʲ должны удовлетворять следующему дополнительному условию: tᵢ / mᵢ ≥ 0.2. После построения всех выборок {X⁰ₒᵦₓᵧ, X⁰ₖₒₙₜₚ}ʲ, они фиксируются для последующего применения на каждой из них всего набора алгоритмов A

---

Далее алгоритм A реализуется как последовательность шагов 1-3.

## Шаг 1. Определение функции попарного сравнения объектов из X:

s: X × X → ℝ (1)

Каждый объект x ∈ X можно сравнить с объектами из выборки X⁰ₒᵦₓᵧ. В результате объекту x можно сопоставить вектор (s(x, x₁), ..., s(x, xₘ)) m₁ первых компонент являются результатом сравнения x с объектами из X⁰₁₍ₒ₎, m₂ следующих являются результатом сравнения x с объектами из X⁰₂₍ₒ₎ и т.д.

## Шаг 2. Определение функции сравнения объектов из x ∈ X с объектами из обучающей выборки X⁰ᵢ₍ₒ₎:

fᵢ: ℝᵐ → ℝ, i ∈ {1, ..., l} (2)

С помощью функций (2) каждому вектору $(s(x, x_1), ..., s(x, x_m)) \in \mathbb{R}^m$ можно сопоставить вектор $(f_1(x), ..., f_l(x)) \in \mathbb{R}^l$.

## Шаг 3. Определение решающего правила $P^A$ в виде:

$P^A: \mathbb{R}^l \to \mathbb{B}_2^l, \mathbb{B}_2=\{0,1\}$ (3)

Вектор $P^A(x) = (P_1^A(x), ..., P_l^A(x))$ в отличие от вектора $P(x)$ называют обычно **классификационным**, тк его значения интерпретируются следующим образом. Считается, что объект $x \in X$ заносится (или не заносится) алгоритмом $A$ в класс $X_i$, если $P_i^A(x) = 1 (= 0)$.

---

## Шаг 4. 
Тестирование определенного на шагах 1-3 алгоритма распознавания $A$ на фиксированной выборке $\{X^0_{обуч}, X^0_{контр}\}^j, j = 1,2, ..., k$.

Инициализация: полагаем $t^0(X^0_{контр})=0$.

### Шаг 4.1. 

Последовательно перебираем все объекты $x \in X^0_{контр}$ и для каждого из них вычисляем:
а) вектор $(s(x, x_1), ..., s(x, x_m))$ для всех $x \in X^0_{обуч}$;
b) вектор $(f_1(x), ..., f_l(x))$ для всех $i \in \{1, ..., l\}$;
c) вектор $P^A(x) = (P_1^A(x), ..., P_l^A(x))$
d) если $P^A(x) = P(x)$, то $t^0(X^0_{контр}) = t^0(X^0_{контр}) + 1$ и переходим к пункту e). В противном случае $t^0(X^0_{контр})$ не меняется и переходим к пункту e).
e) если не все объекты $x \in X^0_{контр}$ исчерпаны, то выполняем шаг 4.1 для следующего объекта контрольной выборки. В противном случае переходим к шагу 4.2.

### Шаг 4.2. Вычисляем 

$\Phi_A(X^0_{контр}) = \frac{t^0(X^0_{контр})}{t}$

величину **функционала качества** $\Phi_A(X^0_{контр}) \in [0, 1]$ и заносим ее в таблицу:

| Разбиение<br>Алгоритм | $\{X^0_{обуч}, X^0_{контр}\}^1$ | $\{X^0_{обуч}, X^0_{контр}\}^2$ |
|:---------------------:|:--------------------------------:|:--------------------------------:|
| $A$                   |                                  |                                  |

Если все выборки $\{X^0_{обуч}, X^0_{контр}\}^j$ исчерпаны, то задача решена в полном объеме. В противном случае выбираем новую выборку $\{X^0_{обуч}, X^0_{контр}\}^j$ и возвращаемся на шаг 4.

# ВАРИАНТЫ ВЫБОРА ФУНКЦИЙ ДЛЯ ШАГОВ (1)-(3) СХЕМЫ АЛГОРИТМОВ

## ВАРИАНТ I. (для пространства $X \subseteq \mathbb{R}^n$)
Выбор функции (1).
- метрика Евклида

$s(x_1, x_2) = (\sum_{i=1}^{n} (x_{1i} -x_{2i})^2)^{1/2}$

- метрика Минковского ($p\in\mathbb{N}$)

$s(x_1, x_2) = (\sum_{i=1}^{n} (x_{1i} -x_{2i})^p)^{1/p}$

Выбор функции (2).
- среднее (м.б. взвешенное) расстояние до класса $X_i$

$f_i(x) = (m_i)^{-1} \sum_{x_j\in X_{i(o)}^0} s(x, x_j)$

- $k$ ближайших соседей  
пусть для класса $X_i$ получен набор $s(X_{i(o)}^0) = \{s(x, x_1), ..., s(x, x_{m_i})\}$;  
переупорядочим набор $s(X_{i(o)}^0)$ по **возрастанию** элементов и поставим ему в соответствие новый набор $\bar{X}_{i(o)}^0$, в котором содержится $k$ первых элементов $x_j \in X_{i(o)}^0$ из полученного в результате переупорядочения набора;  
посчитаем среднее расстояние до класса по новому набору $\bar{X}_{i(o)}^0$

$f_i(x) = (k)^{-1} \sum_{x_j\in\bar{X}_{i(o)}^0} s(x, x_j)$

- по минимальному расстоянию до объектов класса $X_i$

$f_i(x) = \min_{x_j\in X_{i(o)}^0} s(x, x_j)$

Выбор решающего правила (3).
- по минимуму оценки до класса $X_i$

$P_i^A(x) = \begin{cases}
1, \text{если } f_i(x) = \min_{i\in\{1,...,l\}} \{f_1(x), ..., f_l(x)\}; \\
0, \text{в противном случае}
\end{cases}$

---

## ВАРИАНТ II. (для пространства $X \subseteq \mathbb{R}^n$)

Выбор функции (1).
- метрика Хэмминга

$s(x_1, x_2) = \sum_{i=1}^{n} |x_{1i} - x_{2i}|$

Выбор функции (2).
- среднее (м.б. взвешенное) расстояние до класса $X_i$

$f_i(x) = (m_i)^{-1} \sum_{x_j\in X_{i(o)}^0} s(x, x_j)$

- $k$ ближайших соседей  
пусть для класса $X_i$ получен набор $s(X_{i(o)}^0) = \{s(x, x_1), ..., s(x, x_{m_i})\}$;  
переупорядочим набор $s(X_{i(o)}^0)$ по **возрастанию** элементов и поставим ему в соответствие новый набор $\bar{X}_{i(o)}^0$, в котором содержится $k$ первых элементов $x_j \in X_{i(o)}^0$ из полученного в результате переупорядочения набора;  
посчитаем среднее расстояние до класса по новому набору $\bar{X}_{i(o)}^0$

$f_i(x) = (k)^{-1} \sum_{x_j\in\bar{X}_{i(o)}^0} s(x, x_j)$

- по минимальному расстоянию до объектов класса $X_i$
$f_i(x) = \min_{x_j\in X_{i(o)}^0} s(x, x_j)$

Выбор решающего правила (3).
- по минимуму оценки до класса $X_i$
$P_i^A(x) = \begin{cases}
1, \text{если } f_i(x) = \min_{i\in\{1,...,l\}} \{f_1(x), ..., f_l(x)\}; \\
0, \text{в противном случае}
\end{cases}$

## Требования к программному продукту:
1. Любой язык программирования
2. Графический интерфейс **обязателен**;
3. Вывод на экран по запросу всей информации, которая описывает полученное решение.