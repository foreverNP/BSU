# 9.1 Введение

В Главе 7 мы рассмотрели, как создавать масштабируемые спин-блокировки, которые эффективно обеспечивают взаимное исключение даже при интенсивном использовании. Можно подумать, что теперь создать масштабируемые параллельные структуры данных просто: берем последовательную реализацию класса, добавляем поле масштабируемой блокировки и обеспечиваем, чтобы каждый вызов метода получал и освобождал эту блокировку. Такой подход называется крупнозернистой синхронизацией.

Крупнозернистая синхронизация часто работает хорошо, но существуют важные случаи, когда она неэффективна. Проблема в том, что класс, использующий единственную блокировку для управления всеми вызовами методов, не всегда масштабируем, даже если сама блокировка масштабируема. Крупнозернистая синхронизация хорошо работает при низком уровне параллелизма, но если слишком много потоков пытаются одновременно получить доступ к объекту, то объект становится последовательным узким местом, заставляя потоки ждать своей очереди для доступа.

В этой главе представлены несколько полезных методов, которые выходят за рамки крупнозернистой блокировки, позволяя нескольким потокам одновременно получать доступ к одному объекту:

• Мелкозернистая синхронизация: Вместо использования одной блокировки для синхронизации каждого доступа к объекту, мы разделяем объект на независимо синхронизируемые компоненты, позволяя вызовам методов, обращающимся к разным компонентам, выполняться параллельно.

• Оптимистичная синхронизация: Многие объекты, такие как деревья или списки, состоят из нескольких компонентов, связанных ссылками. Некоторые методы ищут определенный компонент (например, узел списка или дерева, содержащий определенный ключ). Один из способов снизить стоимость мелкозернистой блокировки — выполнять поиск без получения каких-либо блокировок. Если метод находит искомый компонент, он блокирует этот компонент, а затем проверяет, не изменился ли компонент в интервале между его проверкой и блокировкой. Эта техника оправдывает себя только в случае, если она успешна чаще, чем нет, поэтому мы называем ее оптимистичной.

• Ленивая синхронизация: Иногда имеет смысл отложить сложную работу. Например, задачу удаления компонента из структуры данных можно разделить на две фазы: компонент логически удаляется простой установкой бита-флага, а позже компонент может быть физически удален путем отсоединения его от остальной части структуры данных.

• Неблокирующая синхронизация: Иногда мы можем полностью исключить блокировки, полагаясь на встроенные атомарные операции, такие как compareAndSet(), для синхронизации.

# 9.3 Параллельные рассуждения

Рассуждения о параллельных структурах данных могут казаться невероятно сложными, но это навык, которому можно научиться. Часто ключом к пониманию параллельной структуры данных является понимание её инвариантов: свойств, которые всегда сохраняются. Мы можем показать, что свойство является инвариантом, продемонстрировав, что:
1. свойство выполняется при создании объекта, и
2. когда свойство установлено, ни один поток не может выполнить шаг, делающий его ложным.

Большинство интересных инвариантов тривиально выполняются при создании списка, поэтому имеет смысл сосредоточиться на том, как инварианты, будучи установленными, сохраняются.

В частности, мы можем проверить, что каждый инвариант сохраняется при каждом вызове методов insert(), remove() и contains(). Этот подход работает только если мы можем предположить, что эти методы — единственные, которые изменяют узлы, свойство, иногда называемое свободой от вмешательства. В алгоритмах списков, рассматриваемых здесь, узлы являются внутренними для реализации списка, поэтому свобода от вмешательства гарантируется, так как пользователи списка не имеют возможности изменять его внутренние узлы.

Мы требуем свободу от вмешательства даже для узлов, которые были удалены из списка, поскольку некоторые из наших алгоритмов позволяют потоку отсоединять узел, в то время как он обходится другими потоками. К счастью, мы не пытаемся повторно использовать узлы списка, которые были удалены из списка, полагаясь вместо этого на сборщик мусора для переработки этой памяти. Описанные здесь алгоритмы работают в языках без сборки мусора, но иногда требуют нетривиальных модификаций, выходящих за рамки этой главы. Мы обсуждаем вопросы, возникающие в отсутствие сборки мусора, и способы их решения в Главе 19.

При рассуждении о реализациях параллельных объектов важно понимать различие между абстрактным значением объекта (здесь — множеством элементов) и его конкретным представлением (здесь — списком узлов).

Не каждый список узлов является осмысленным представлением множества. Инвариант представления алгоритма характеризует, какие представления имеют смысл как абстрактные значения. Если a и b — узлы, мы говорим, что a указывает на b, если поле next узла a является ссылкой на b. Мы говорим, что b достижим, если существует последовательность узлов, начинающаяся с head и заканчивающаяся в b, где каждый узел в последовательности указывает на своего преемника.

Алгоритмы множеств в этой главе требуют следующих инвариантов (некоторые требуют большего, как объясняется далее):

1. Ключ любого узла в списке меньше ключа его преемника (если таковой имеется). Это означает, что узлы в списке отсортированы по ключу, и ключи уникальны.
2. Ключ любого элемента, добавляемого, удаляемого или искомого, больше ключа head и меньше ключа tail. (Следовательно, узлы-часовые не добавляются и не удаляются.)

Рассматривайте инвариант представления как контракт между методами объекта. Каждый вызов метода сохраняет инвариант и полагается на другие методы для сохранения инварианта. Таким образом, мы можем рассуждать о каждом методе изолированно, не рассматривая все возможные способы их взаимодействия.

Учитывая список, удовлетворяющий инварианту представления, какое множество он представляет? Значение такого списка определяется отображением абстракции, переносящим списки, удовлетворяющие инварианту представления, на множества. Здесь отображение абстракции простое: элемент находится в множестве тогда и только тогда, когда он (в узле) достижим из head.

Какие свойства безопасности и живучести нам нужны? Для безопасности мы хотим линеаризуемости. Как мы видели в Главе 3, чтобы показать, что параллельная структура данных является линеаризуемой реализацией последовательного объекта, достаточно определить точку линеаризации — атомарный шаг, где вызов метода "вступает в силу"; мы говорим, что он линеаризуется в этой точке. Этот шаг может быть чтением, записью или более сложной атомарной операцией. Рассматривая любую историю выполнения множества на основе списка, должно быть так, что если отображение абстракции применяется к представлению в точках линеаризации, результирующая последовательность состояний и вызовов методов определяет допустимое последовательное выполнение множества. Здесь add(a) добавляет a в абстрактное множество, remove(a) удаляет a из абстрактного множества, а contains(a) возвращает true или false в зависимости от того, был ли a уже в множестве.

Различные алгоритмы списков обеспечивают разные гарантии прогресса. Некоторые используют блокировки, и требуется осторожность, чтобы обеспечить их свободу от взаимоблокировок и голодания. Некоторые неблокирующие алгоритмы списков вообще не используют блокировки, в то время как другие ограничивают блокировку определенными методами.

Вот краткое изложение неблокирующих свойств, которые мы используем, из Главы 3:

• Метод является wait-free (свободным от ожидания), если каждый вызов завершается за конечное число шагов.
• Метод является lock-free (свободным от блокировок), если некоторый вызов всегда завершается за конечное число шагов.

Теперь мы готовы рассмотреть различные алгоритмы множеств на основе списков. Мы начинаем с алгоритмов, использующих крупнозернистую синхронизацию, и последовательно улучшаем их, чтобы уменьшить гранулярность блокировки, кульминацией чего является неблокирующий алгоритм. Формальные доказательства корректности выходят за рамки этой книги. Вместо этого мы сосредотачиваемся на неформальных рассуждениях, полезных в повседневном решении проблем.

Как упоминалось, в каждом из этих алгоритмов методы обходят список, используя две локальные переменные: curr — текущий узел, и pred — его предшественник. Поскольку эти переменные локальные, каждый поток имеет свои собственные экземпляры; мы используем predA и currA для обозначения экземпляров, используемых потоком A.