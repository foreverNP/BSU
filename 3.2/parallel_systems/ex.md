### 1. Параллельное программирование как способ повышения эффективности программы

**Параллельное программирование** — это техника написания программ, при которой несколько вычислительных процессов выполняются одновременно. Основная цель — **повышение производительности** за счет распараллеливания задач и их одновременного выполнения на нескольких процессорных ядрах или даже на нескольких компьютерах. Это позволяет значительно сократить общее время выполнения программы, особенно для ресурсоемких задач, таких как научные вычисления, обработка больших данных и рендеринг графики.

---

### 2. Многопоточная программа как параллельная программа

**Многопоточная программа** является частным случаем параллельной программы. В такой программе несколько потоков выполнения (тредов) работают в общем адресном пространстве одного процесса. Каждый поток имеет свой собственный стек и набор регистров, но разделяет общие данные с другими потоками. Это позволяет эффективно распараллеливать задачи в рамках одного приложения, используя многоядерные процессоры.

---

### 3. Модель делегирования: подход 1 и подход 2

**Модель делегирования** предполагает наличие одного главного (управляющего) потока и одного или нескольких рабочих потоков.

* **Подход 1 (Статическое распределение):** Главный поток заранее разделяет всю задачу на независимые части и раздает их рабочим потокам. Рабочие потоки выполняют свои задания и завершаются. Этот подход прост в реализации, но может быть неэффективен, если задачи имеют разную сложность, что приведет к простою некоторых потоков.
* **Подход 2 (Динамическое распределение):** Главный поток создает пул задач. Рабочие потоки берут по одной задаче из пула, выполняют ее и запрашивают следующую. Это обеспечивает более равномерную загрузку рабочих потоков, но требует дополнительной синхронизации для доступа к пулу задач.

---

### 4. Модель с равноправными узлами: подход 1 и подход 2

В **модели с равноправными узлами (Peer-to-Peer)** все потоки имеют одинаковые права и обязанности. Каждый поток выполняет как управляющие, так и рабочие функции.

* **Подход 1 (Общая очередь задач):** Все потоки берут задачи из одной общей, централизованной очереди. Этот подход прост, но общая очередь может стать "узким местом" при большом количестве потоков.
* **Подход 2 (Локальные очереди задач):** У каждого потока есть своя собственная очередь задач. Если локальная очередь опустела, поток может "украсть" задачу из очереди другого, более загруженного потока (work-stealing). Это улучшает масштабируемость и снижает contention.

---

### 5. Модель "Конвейер" (Pipeline)

**Модель "Конвейер"** организует потоки в виде последовательной цепочки, где результат работы одного потока является входными данными для следующего. Каждый поток в конвейере представляет собой один из этапов обработки данных. Эта модель эффективна для задач, которые можно разбить на последовательные стадии, например, при обработке потоковых данных (видео, сетевые пакеты).

---

### 6. Модель "Производитель-Потребитель" (Producer-Consumer)

Эта модель описывает взаимодействие двух типов потоков через общую структуру данных (буфер или очередь):

* **Производители (Producers):** Генерируют данные и помещают их в буфер.
* **Потребители (Consumers):** Извлекают данные из буфера и обрабатывают их.

Необходима синхронизация для управления доступом к буферу, чтобы производители не добавляли данные в переполненный буфер, а потребители не пытались извлечь данные из пустого.

---

### 7. Анализ эффективности использования параллелизма

Эффективность параллельной программы оценивается с помощью нескольких метрик:

* **Ускорение (Speedup):** Отношение времени выполнения последовательной программы ($T_s$) ко времени выполнения параллельной программы на $p$ процессорах ($T_p$). Идеальное ускорение равно $p$.
    $$S_p = \frac{T_s}{T_p}$$
* **Эффективность (Efficiency):** Ускорение, деленное на количество процессоров. Показывает, насколько хорошо используются вычислительные ресурсы.
    $$E_p = \frac{S_p}{p}$$
* **Закон Амдала:** Описывает теоретический предел ускорения, который можно получить при распараллеливании. Ускорение ограничено долей последовательного кода в программе.
* **Закон Густафсона:** Утверждает, что с ростом числа процессоров можно решать задачи большего объема за то же время, и доля параллельных вычислений растет.

---

### 8. Методика Яна Фостера

Гергель В.П. Высокопроизводительные вычисления для многоядерных многопроцессорных 
систем. Гергель, 3.2. Этапы разработки параллельных алгоритмов (стр. 60)


**Методика Яна Фостера** — это четырехэтапный подход к проектированию параллельных алгоритмов:

1.  **Partitioning (Разбиение):** Декомпозиция задачи и данных на множество мелких частей.
2.  **Communication (Коммуникация):** Определение обменов данными, необходимых между этими частями.
3.  **Agglomeration (Укрупнение):** Объединение мелких частей и их коммуникаций в более крупные задачи для уменьшения накладных расходов на взаимодействие.
4.  **Mapping (Отображение):** Распределение укрупненных задач по конкретным процессорам или потокам с целью минимизации времени выполнения и максимизации загрузки процессоров.

---

### 9. Способы декомпозиции задачи

**Декомпозиция** — это процесс разделения задачи на более мелкие подзадачи, которые могут выполняться параллельно.

* **Декомпозиция по данным (Data Decomposition):** Каждому потоку назначается свой фрагмент данных для обработки. Например, при обработке массива каждый поток работает со своей частью этого массива.
* **Декомпозиция по задачам (Task Decomposition):** Задача разбивается на функционально независимые части. Каждый поток выполняет свою уникальную функцию. Например, в графическом редакторе один поток может отвечать за рендеринг, а другой — за обработку ввода от пользователя.

---

### 10. Механизмы синхронизации

**Синхронизация** необходима для координации работы потоков и обеспечения корректного доступа к общим ресурсам. Основные механизмы:

* **Мьютексы (Mutexes):** Обеспечивают взаимное исключение, гарантируя, что только один поток в каждый момент времени может выполнять критическую секцию кода.
* **Семафоры (Semaphores):** Обобщение мьютексов. Позволяют ограниченному числу потоков одновременно получать доступ к ресурсу.
* **Условные переменные (Condition Variables):** Позволяют потокам приостанавливать свое выполнение до тех пор, пока не будет выполнено некоторое условие.
* **Барьеры (Barriers):** Блокируют группу потоков до тех пор, пока все потоки этой группы не достигнут барьера.
* **Атомарные операции:** Операции (например, инкремент), которые выполняются как единое, неделимое действие, что устраняет необходимость в блокировках для простых модификаций.

---

### 11. Ошибки параллельного программирования

* **Состояние гонки (Race Condition):** Результат программы зависит от непредсказуемой последовательности выполнения потоков, обращающихся к общим данным.
* **Взаимная блокировка (Deadlock):** Два или более потока бесконечно ожидают друг друга, так как каждый из них заблокировал ресурс, необходимый другому.
* **Голодание (Starvation):** Один или несколько потоков не могут получить доступ к ресурсу, так как он постоянно занят другими потоками.
* **Инверсия приоритетов (Priority Inversion):** Низкоприоритетный поток удерживает ресурс, необходимый высокоприоритетному потоку, но не может его освободить, так как вытесняется потоками со средним приоритетом.

---

### 12. Способы завершения потоков

* **Естественное завершение:** Поток завершается, когда его основная функция (например, `run()` в Java или функция, переданная в `std::thread` в C++) заканчивает свое выполнение. Это **предпочтительный** способ.
* **Завершение по флагу:** В цикле выполнения потока периодически проверяется значение флага (например, `volatile boolean isRunning`). Главный поток может изменить значение этого флага, чтобы сигнализировать о необходимости завершения.
* **Прерывание (Interruption):** В Java можно вызвать метод `interrupt()` у потока. Это устанавливает флаг прерывания. Поток должен сам проверить этот флаг (`isInterrupted()`) и корректно завершить свою работу. В C++20 появился `std::jthread`, который поддерживает механизм прерывания через `stop_token`.
* **Принудительное завершение (Deprecated):** Методы типа `stop()` в Java являются устаревшими и **опасными**, так как они могут оставить разделяемые ресурсы в несогласованном состоянии.

---

### 13. Механизмы синхронизации в Java

* **Ключевое слово `synchronized`:** Используется для создания критических секций (синхронизированных методов или блоков). Работает на основе встроенных мониторов объектов.
* **`volatile`:** Гарантирует, что изменения переменной одним потоком будут видны другим потокам. Не обеспечивает атомарность.
* **Классы из пакета `java.util.concurrent.locks`:**
    * **`ReentrantLock`:** Более гибкая и мощная альтернатива `synchronized`.
    * **`ReadWriteLock`:** Позволяет одновременный доступ на чтение нескольким потокам, но эксклюзивный доступ для записи.
    * **`Semaphore`:** Реализация семафора.
    * **`CountDownLatch`:** Защелка обратного отсчета, позволяет потокам ждать завершения операций в других потоках.
    * **`CyclicBarrier`:** Позволяет группе потоков ждать друг друга в определенной точке.
    * **`Phaser`:** Более гибкая версия барьера.
* **Атомарные классы (`java.util.concurrent.atomic`):** Классы `AtomicInteger`, `AtomicLong`, `AtomicBoolean` и др., предоставляющие атомарные операции.

---

### 14. Механизмы синхронизации в C++

* **`<mutex>`:**
    * **`std::mutex`:** Базовый мьютекс.
    * **`std::recursive_mutex`:** Позволяет одному потоку захватывать мьютекс несколько раз.
    * **`std::shared_mutex` (C++17):** Аналог `ReadWriteLock` в Java.
* **`<shared_mutex>` (C++14):** Предоставляет `std::shared_mutex`.
* **`<condition_variable>`:**
    * **`std::condition_variable`:** Условная переменная для работы с `std::unique_lock`.
* **`<atomic>`:**
    * **`std::atomic<T>`:** Шаблон для создания атомарных типов (`std::atomic<bool>`, `std::atomic<int>` и т.д.).
* **`<semaphore>` (C++20):**
    * **`std::counting_semaphore`**, **`std::binary_semaphore`**.
* **`<barrier>` (C++20):**
    * **`std::barrier`**.
* **`<latch>` (C++20):**
    * **`std::latch`** (аналог `CountDownLatch`).

---

### 15. Потокобезопасные структуры данных в Java

Находятся в пакете `java.util.concurrent`:

* **`ConcurrentHashMap`:** Высокопроизводительная хэш-таблица.
* **`CopyOnWriteArrayList`**, **`CopyOnWriteArraySet`:** Потокобезопасные списки и множества, где любая модификация создает новую копию базового массива. Эффективны при редких записях и частых чтениях.
* **Блокирующие очереди (Blocking Queues):**
    * **`ArrayBlockingQueue`:** Очередь на базе массива фиксированного размера.
    * **`LinkedBlockingQueue`:** Очередь на базе связанного списка (опционально ограниченная).
    * **`PriorityBlockingQueue`:** Неограниченная очередь с поддержкой приоритетов.
    * **`SynchronousQueue`:** Очередь без внутреннего буфера. Каждая операция вставки ждет соответствующей операции извлечения.

---

### 16. Потокобезопасные структуры данных в C++

Стандартная библиотека C++ **не предоставляет** готовых потокобезопасных контейнеров (как `ConcurrentHashMap` в Java). Программист должен сам обеспечивать потокобезопасность при доступе к стандартным контейнерам (`std::vector`, `std::map` и т.д.) с помощью мьютексов или других примитивов синхронизации. Однако, операции с отдельными элементами `std::atomic` являются потокобезопасными.

---

### 17. Синхронизация потоков ввода-вывода

Потоки стандартного ввода-вывода (например, `System.out` в Java, `std::cout` в C++) обычно являются потокобезопасными на уровне отдельных операций (например, вызов `println()` или `operator<<`). Однако, последовательность из нескольких операций вывода не будет атомарной.

**Пример проблемы:** Два потока выводят "Hello" и "World". Без синхронизации вывод может перемешаться: "HWeolrllod".

**Решение:** Использовать явные блокировки (мьютекс или `synchronized` блок) для защиты последовательности операций ввода-вывода, чтобы гарантировать, что вывод от одного потока не будет прерван выводом от другого.

```java
// Java
synchronized (System.out) {
    System.out.print("Hello, ");
    System.out.println("World!");
}
```

```cpp
// C++
std::mutex cout_mutex;
{
    std::lock_guard<std::mutex> lock(cout_mutex);
    std::cout << "Hello, " << "World!" << std::endl;
}
```

---

### 18. Реализация модели делегирования в Java

Модель делегирования (Master/Worker) легко реализуется с помощью `ExecutorService`.

* **Подход 2 (Динамическое распределение):**
    1.  **Master:** Создает `ExecutorService` (например, `Executors.newFixedThreadPool(N)`), который управляет пулом рабочих потоков.
    2.  **Master:** Создает задачи (объекты `Callable` или `Runnable`) и отправляет их на выполнение с помощью `submit()`.
    3.  **Workers (потоки из пула):** Автоматически берут задачи из внутренней очереди `ExecutorService` и выполняют их.
    4.  **Master:** Может получить результаты через объекты `Future`, возвращаемые методом `submit()`.
    5.  По завершении всех задач `Master` останавливает `ExecutorService` с помощью `shutdown()`.

---

### 19. Реализация модели делегирования в C++

В C++ можно использовать `std::thread` и контейнер для задач.

* **Подход 2 (Динамическое распределение):**
    1.  **Master:** Создает потокобезопасную очередь задач (например, `std::queue` защищенную `std::mutex`).
    2.  **Master:** Создает и запускает несколько рабочих потоков (`std::thread`).
    3.  **Master:** Помещает задачи (например, `std::function<void()>`) в очередь.
    4.  **Workers:** В цикле извлекают задачи из очереди (синхронизированно) и выполняют их. Когда очередь пуста, они могут либо ждать, либо завершаться.
    5.  **Master:** По завершении добавления задач может поместить специальные "сигналы завершения" в очередь, чтобы рабочие потоки вышли из цикла и завершились.
    6.  **Master:** Ждет завершения всех рабочих потоков с помощью `join()`.

---

### 20. Реализация модели Производитель-Потребитель в Java

Используются блокирующие очереди из `java.util.concurrent`.

1.  Создается экземпляр `BlockingQueue` (например, `ArrayBlockingQueue`), который будет общим буфером.
2.  **Производитель:** В своем методе `run()` генерирует данные и помещает их в очередь с помощью метода `put()`. Этот метод автоматически заблокирует поток, если очередь полна, и дождется, пока в ней не появится место.
3.  **Потребитель:** В своем методе `run()` извлекает данные из очереди с помощью метода `take()`. Этот метод заблокирует поток, если очередь пуста, и дождется появления данных.

---

### 21. Реализация модели Производитель-Потребитель в C++

Используются `std::mutex` и `std::condition_variable`.

1.  Создается общий буфер (например, `std::queue`), мьютекс (`std::mutex`) для его защиты и две условные переменные (`std::condition_variable`): одна для сигнализации о том, что буфер не пуст, и другая — о том, что он не полон.
2.  **Производитель:**
    * Захватывает мьютекс.
    * Ждет на условной переменной, пока в буфере есть место (`while (queue.size() == MAX_SIZE) { cond_var_not_full.wait(lock); }`).
    * Добавляет элемент в очередь.
    * Оповещает один из ожидающих потребителей (`cond_var_not_empty.notify_one()`).
    * Освобождает мьютекс.
3.  **Потребитель:**
    * Захватывает мьютекс.
    * Ждет на условной переменной, пока в буфере не появятся данные (`while (queue.empty()) { cond_var_not_empty.wait(lock); }`).
    * Извлекает элемент из очереди.
    * Оповещает один из ожидающих производителей (`cond_var_not_full.notify_one()`).
    * Освобождает мьютекс.

---

### 22. Классификация средств поддержки многопоточности в Java

* **Низкоуровневые примитивы:**
    * `Thread`: Основной класс для создания и управления потоками.
    * `synchronized`, `wait()`, `notify()`, `notifyAll()`: Базовые механизмы мониторов.
    * `volatile`: Для обеспечения видимости переменных.
* **Высокоуровневые API (`java.util.concurrent`):**
    * **Исполнители (`Executor` Framework):** `ExecutorService`, `ThreadPoolExecutor` для управления пулами потоков.
    * **Примитивы синхронизации:** `Lock`, `Semaphore`, `CountDownLatch`, `CyclicBarrier`.
    * **Потокобезопасные коллекции:** `ConcurrentHashMap`, `BlockingQueue` и др.
    * **Атомарные переменные:** Пакет `java.util.concurrent.atomic`.
    * **Средства для асинхронного программирования:** `Future`, `CompletableFuture`.
    * **Fork/Join Framework:** Для рекурсивного распараллеливания задач.

---

### 23. Классификация средств поддержки многопоточности в C++

* **Низкоуровневые примитивы (C++11 и выше):**
    * `std::thread`: Класс для создания и управления потоками.
    * `std::mutex`, `std::condition_variable`: Основные примитивы синхронизации.
    * `std::atomic`: Для атомарных операций.
* **Высокоуровневые средства:**
    * **Асинхронные задачи:** `std::async`, `std::future`, `std::promise`. Позволяют запускать задачи асинхронно и получать их результат.
    * **Блокирующие примитивы (C++20):** `std::latch`, `std::barrier`, `std::semaphore`.
    * **Потокобезопасность:** Отсутствуют готовые потокобезопасные контейнеры, требуется ручная синхронизация.
* **Библиотеки и расширения:**
    * **OpenMP:** Директивная модель для распараллеливания циклов и участков кода.
    * **Intel TBB (Threading Building Blocks):** Библиотека с богатым набором параллельных алгоритмов и контейнеров.

---

### 24. Программный интерфейс OpenMP

**OpenMP (Open Multi-Processing)** — это стандарт API для написания параллельных программ на языках C, C++ и Fortran. Он основан на **директивах компилятора**.

* **Модель программирования:** OpenMP использует модель "вилочного" выполнения (fork-join). Программа начинается с одного главного потока. Когда встречается параллельный регион (обозначенный директивой), главный поток создает группу рабочих потоков. В конце параллельного региона рабочие потоки завершаются, и выполнение продолжает только главный поток.
* **Основные компоненты:**
    * **Директивы (`#pragma omp ...`):** Указывают компилятору, как распараллеливать код. Например, `#pragma omp parallel for` распараллеливает цикл `for`.
    * **Функции времени выполнения (`omp_...`):** Функции для управления средой OpenMP (например, `omp_get_thread_num()` для получения номера потока).
    * **Переменные окружения:** Для настройки поведения OpenMP-программ во время выполнения.

---

### 25. Поддержка шаблонов параллельного программирования в OpenMP

OpenMP напрямую поддерживает множество распространенных шаблонов:

* **Параллельные циклы (Loop Parallelism):** Основное применение OpenMP. Директива `#pragma omp for` автоматически распределяет итерации цикла между потоками.
* **Модель делегирования (Master/Worker):**
    * Директива `#pragma omp parallel` создает группу рабочих потоков.
    * Конструкции `#pragma omp master` или `#pragma omp single` позволяют выполнять код только одному (главному) потоку, который может раздавать задачи.
* **Конвейер (Pipeline):** Можно реализовать с помощью директивы `#pragma omp sections`, где каждая секция (`#pragma omp section`) представляет собой один этап конвейера.
* **Синхронизация:**
    * `#pragma omp critical`: Определяет критическую секцию.
    * `#pragma omp atomic`: Для атомарного обновления одной переменной.
    * `#pragma omp barrier`: Явный барьер для синхронизации всех потоков.
    * `#pragma omp flush`: Обеспечивает согласованность представлений памяти между потоками.

----------------------------------------

### 1. Результат вызова `notify()` без `wait()`

Если вызвать метод `notify()` на объекте-мониторе, на котором ни один поток не ожидает (то есть не вызывался `wait()`), **ничего не произойдет**. Вызов будет просто проигнорирован.

Однако важно помнить, что вызывать `notify()` (как и `wait()`) можно только из синхронизированного блока или метода, то есть текущий поток должен владеть монитором объекта. Если это условие не выполнено, будет выброшено исключение `IllegalMonitorStateException`.

---

### 2. Аналог `wait/notify` для `Lock`

У интерфейса `Lock` есть более гибкий и мощный механизм — **объекты `Condition`**.

* `Condition` привязывается к конкретному экземпляру `Lock`.
* Метод `condition.await()` является аналогом `wait()`.
* Метод `condition.signal()` является аналогом `notify()`.
* Метод `condition.signalAll()` является аналогом `notifyAll()`.

Этот механизм позволяет создавать несколько разных условий ожидания для одной и той же блокировки, что невозможно сделать с `synchronized`.

---

### 3. Гранулярность (степень детализации) блокировки

**Гранулярность блокировки** — это мера, определяющая, какой объем данных защищается одной блокировкой.

---

### 4. Влияние гранулярности блокировки

Гранулярность напрямую влияет на **баланс между накладными расходами и уровнем параллелизма**:

* **Крупная гранулярность** (одна блокировка на всю структуру данных): Низкие накладные расходы на управление блокировками, но низкий уровень параллелизма, так как потоки часто будут блокироваться.
* **Мелкая гранулярность** (отдельная блокировка для каждого элемента данных): Высокий уровень параллелизма, но и высокие накладные расходы на захват/освобождение множества блокировок и на потребление памяти.

---

### 5. Пояснение термина «крупная гранулярность блокировки»

**«Крупная гранулярность»** (Coarse-grained locking) означает, что одна блокировка используется для защиты большого участка данных или нескольких независимых ресурсов.

**Пример:** Блокировка всего объекта `HashMap` для любой операции, вместо блокировки отдельных его сегментов (бакетов).

---

### 6. Пояснение термина «низкая степень детализации блокировки»

Это синоним термина **«крупная гранулярность блокировки»**. Оба термина означают, что блокировка не детализирована и охватывает большой объем данных.

---

### 7. Реализация lock-free счетчика с `AtomicInteger`

Lock-free означает, что для синхронизации не используются блокировки (мьютексы). Класс `AtomicInteger` идеально для этого подходит, так как предоставляет атомарные операции.

```java
import java.util.concurrent.atomic.AtomicInteger;

/**
 * Потокобезопасный счетчик без использования блокировок.
 */
public class LockFreeCounter {
    private final AtomicInteger counter = new AtomicInteger(0);

    /**
     * Атомарно увеличивает значение счетчика на 1.
     * @return Новое значение счетчика.
     */
    public int increment() {
        return counter.incrementAndGet();
    }

    /**
     * Возвращает текущее значение счетчика.
     * @return Текущее значение.
     */
    public int getValue() {
        return counter.get();
    }
}
```

---

### 8. Распараллеливание цикла

**а. Что под этим понимают:**
Это техника, при которой итерации цикла распределяются между несколькими потоками для одновременного выполнения. Цель — ускорить выполнение цикла за счет параллельной обработки данных.

**б. Когда возможно:**
Распараллеливание цикла возможно только тогда, когда **итерации цикла независимы друг от друга**. Это означает, что результат выполнения одной итерации не должен влиять на результат любой другой итерации. Если существует зависимость по данным между итерациями (loop-carried dependency), простое распараллеливание приведет к некорректным результатам.

---

### 9. Технология OpenMP: Что такое параллельный регион

**Параллельный регион** в OpenMP — это блок кода, который предназначен для выполнения несколькими потоками одновременно. Он создается с помощью директивы `#pragma omp parallel`. Когда выполнение программы доходит до этого блока, главный поток создает команду рабочих потоков, и каждый поток из этой команды выполняет код внутри региона.

---

### 10. Как работает директива `#pragma omp parallel for`

Эта директива является комбинацией двух директив: `parallel` и `for`.

1.  `#pragma omp parallel`: Создает параллельный регион, запуская команду потоков.
2.  `#pragma omp for`: Указывает, что следующий за директивой цикл `for` должен быть распараллелен. OpenMP автоматически делит итерации этого цикла между потоками, созданными на первом шаге.

В результате каждая итерация цикла выполняется одним из потоков в команде.

---

### 11. Синхронизация стандартного выходного потока

Стандартные потоки вывода (`System.out` в Java, `std::cout` в C++) являются потокобезопасными на уровне отдельных вызовов, но последовательность вызовов не атомарна. Чтобы избежать "перемешивания" вывода от разных потоков, нужно синхронизировать целый блок операций.

**В Java:**

```java
public void printMessage(String threadName, String message) {
    // Используем сам объект System.out в качестве монитора
    synchronized (System.out) {
        System.out.print(threadName + ": ");
        System.out.println(message);
    }
}
```

---

### 12. Алгоритм планирования цикла `for` в OpenMP

**а. Что это такое:**
Это стратегия (алгоритм), которую OpenMP использует для распределения итераций цикла между потоками в команде. Она задается с помощью опции `schedule`.

**б. Опишите ДВА алгоритма:**

1.  **`static` (Статическое планирование):** Итерации делятся на блоки (чанки) равного размера, и эти блоки заранее распределяются между потоками. Это эффективно, если все итерации занимают примерно одинаковое время, так как накладные расходы на распределение минимальны.
2.  **`dynamic` (Динамическое планирование):** Итерации также делятся на блоки, но потоки запрашивают по одному блоку "на лету", по мере освобождения. Это полезно, когда время выполнения итераций сильно отличается. Динамическое планирование лучше балансирует нагрузку, но имеет более высокие накладные расходы.

---

### 13. Как OpenMP управляет количеством потоков

Количество потоков в параллельном регионе можно контролировать несколькими способами (в порядке убывания приоритета):

1.  **Клауза `num_threads(N)`:** Добавляется к директиве `#pragma omp parallel num_threads(4)` и задает количество потоков для конкретного региона.
2.  **Функция `omp_set_num_threads(N)`:** Устанавливает количество потоков для всех последующих параллельных регионов, если они не используют клаузу `num_threads`.
3.  **Переменная окружения `OMP_NUM_THREADS`:** Задает количество потоков по умолчанию для всей программы.
4.  **Настройки по умолчанию:** Если ничего из вышеперечисленного не задано, OpenMP сам определяет количество потоков, обычно равное количеству ядер процессора.

---

### 14. `reduction` в OpenMP

**а. Что будет результатом выполнения кода:**
Клауза `reduction(operator:variable)` создает приватную копию переменной `variable` для каждого потока. В конце параллельного региона все приватные копии объединяются в одну с помощью указанного оператора (`+`, `*`, `&` и т.д.), и результат записывается в исходную общую переменную.

**б. Преимущества использования `reduction`:**
Главное преимущество — **эффективное и безопасное избежание состояния гонки**. Вместо того чтобы защищать общую переменную мьютексом на каждой итерации (что очень медленно), каждый поток работает со своей быстрой локальной копией. Синхронизация требуется только один раз в самом конце. Это проще в написании и гораздо производительнее.

---

### 15. Можно ли участок кода распараллелить с помощью директивы OpenMP

*(Для точного ответа на этот и следующие два вопроса нужен сам код)*

**Общий ответ:** Участок кода можно распараллелить, если выполняемые в нем задачи **независимы** друг от друга. Для циклов это означает отсутствие зависимостей между итерациями. Для блоков кода (`sections`) — отсутствие зависимостей между задачами в разных секциях. Если зависимости есть, нужна явная синхронизация, что может свести на нет выгоду от распараллеливания.

---

### 16. и 17. Найдите ошибки

*(Без кода дать точный ответ невозможно)*

**Типичные ошибки в многопоточном коде:**

* **Состояние гонки (Race Condition):** Несколько потоков изменяют общие данные без синхронизации.
* **Взаимная блокировка (Deadlock):** Два или более потока циклически ожидают ресурсы, захваченные друг другом.
* **Неправильное использование примитивов синхронизации:** Например, использование `notify()` вместо `notifyAll()`, что может привести к "потере" сигналов.
* **Отсутствие `volatile`:** Изменения общей переменной в одном потоке могут быть не видны другому из-за кеширования.
* **Некорректная обработка исключений:** Блокировка может остаться не освобожденной, если в критической секции произошло исключение.

---

### 18. Пример контейнера данных для структуры данных Стек

В Java для реализации потокобезопасного стека идеально подходит класс **`java.util.concurrent.ConcurrentLinkedDeque`**. Он реализует интерфейс `Deque` (двухсторонняя очередь) и является полностью неблокирующим. Его методы `push()` и `pop()` работают как стековые операции и являются потокобезопасными.

---

### 19. Проблемы многопоточности/синхронизации

* **Race Condition (Состояние гонки):** Непредсказуемый результат из-за конкурентного доступа к общим данным.
* **Deadlock (Взаимная блокировка):** Вечное ожидание потоками друг друга.
* **Livelock (Живая блокировка):** Потоки постоянно меняют свое состояние в ответ на действия друг друга, но не выполняют полезной работы.
* **Starvation (Голодание):** Один или несколько потоков не могут получить доступ к ресурсу, так как он постоянно занят другими потоками.
* **Priority Inversion (Инверсия приоритетов):** Низкоприоритетный поток удерживает ресурс, необходимый высокоприоритетному.

---

### 20. Два аспекта при разработке конкурентных структур данных

1.  **Корректность (Correctness):** Гарантия потокобезопасности. Структура данных должна всегда оставаться в согласованном состоянии, независимо от порядка выполнения потоков. Это включает в себя отсутствие состояний гонки, корректную видимость изменений между потоками и т.д.
2.  **Производительность (Performance):** Структура должна обеспечивать высокий уровень параллелизма и хорошо масштабироваться с ростом числа потоков. Это достигается за счет минимизации времени, проводимого потоками в заблокированном состоянии, и уменьшения "точек спора" (contention).

---

### 21. C++17: Автоматическое распараллеливание стандартных алгоритмов

**а. Что это:**
В C++17 многие алгоритмы из стандартной библиотеки (STL) получили перегруженные версии, которые могут выполняться параллельно. Это позволяет распараллелить код без использования низкоуровневых потоков или сложных библиотек вроде OpenMP.

**б. Как использовать:**
Для этого нужно передать в качестве первого аргумента алгоритма специальный объект — **политику выполнения (execution policy)**. Например:
`std::execution::par` — разрешает параллельное выполнение.
`std::execution::par_unseq` — разрешает параллельное и векторизованное выполнение.

```cpp
#include <vector>
#include <algorithm>
#include <execution>

std::vector<int> data = { /* ... много данных ... */ };

// Распараллелить сортировку с помощью политики std::execution::par
std::sort(std::execution::par, data.begin(), data.end());
```

**в. Когда использовать:**
Это эффективно на **больших объемах данных**, когда накладные расходы на создание и синхронизацию потоков окупаются выигрышем от параллельных вычислений. Операции внутри алгоритма должны быть достаточно "тяжелыми" и независимыми. Для маленьких коллекций данных или очень простых операций выигрыша может не быть или код даже замедлится.

---

### 22. Предложить реализацию `BlockingQueue`

Вот концептуальная реализация блокирующей очереди на основе `Lock` и `Condition`.

```java
import java.util.LinkedList;
import java.util.Queue;
import java.util.concurrent.locks.Condition;
import java.util.concurrent.locks.Lock;
import java.util.concurrent.locks.ReentrantLock;

public class MyBlockingQueue<T> {
    private final Queue<T> queue;
    private final int capacity;
    private final Lock lock = new ReentrantLock();
    private final Condition notFull = lock.newCondition();
    private final Condition notEmpty = lock.newCondition();

    public MyBlockingQueue(int capacity) {
        this.capacity = capacity;
        this.queue = new LinkedList<>();
    }

    public void put(T item) throws InterruptedException {
        lock.lock();
        try {
            // Ждем, пока в очереди появится место
            while (queue.size() == capacity) {
                notFull.await();
            }
            queue.add(item);
            // Сигнализируем, что очередь больше не пуста
            notEmpty.signal();
        } finally {
            lock.unlock();
        }
    }

    public T take() throws InterruptedException {
        lock.lock();
        try {
            // Ждем, пока в очереди появятся элементы
            while (queue.isEmpty()) {
                notEmpty.await();
            }
            T item = queue.remove();
            // Сигнализируем, что в очереди появилось место
            notFull.signal();
            return item;
        } finally {
            lock.unlock();
        }
    }
}
```